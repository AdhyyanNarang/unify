{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we hope to find a relation between data poisoning and data evasion examples. Even though these two classes of adversarial attacks are completed by different optimization formulations,\n",
    "\n",
    "Hypothesis: Both add meaningful perturbations in the \"unexplored\" parts of the data to trick the model into misclassifying examples.\n",
    "\n",
    "It is well known that adversarial training i.e the inclusion of adversarial examples into the training set acts as a kind of regularizer and improves robustness in defense against data evasion attacks.\n",
    "\n",
    "To explicitize the relationship between data poisoning and data evasion attacks, we are going to try to examine the effects of crossing these two attacks on the same learning process by testing the following sub-hypotheses:\n",
    "\n",
    "1. Inclusion of correctly labeled adversarial examples in the training set prior to data poisoning increases the model's performance against poisoning attacks. (Methods that defend against advesarial examples also defend against poisoning)\n",
    "2. (??) (Methods that defend against poisoning examples also defend against adversarial examples)\n",
    "3. Inclusion of wrongly labeled adversarial examples in the training set acts as a data poisoning attack. (Adversarial examples function as poisoning examples as well).\n",
    "4. (??) Poisoning examples function as adversarial examples as well.\n",
    "\n",
    "The aim is not to create a defense mechanism for one or the other. Instead, we hope to further exploration to gain some more insight into the nature of these two attacks. Because currently in the arms race, the attackers of models are easily winning.. which means that it is probably a good idea to take a break from the battle and gain some more knowledge before we go back out into the bloodshed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.utils_tf import model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import AccuracyReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure out how to poison the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the MNIST dataset/ Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0\n",
    "\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3971 - acc: 0.8823: 0s - loss: 0.4002 - acc: 0.8\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2187 - acc: 0.9346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x181898c0f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 64us/step\n",
      "Test accuracy: 0.9618\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1836633780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poison the data [Steinhardt, Koh] Influence functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_with_influence_proj_gradient_step(model, test_idx, indices_to_poison, \n",
    "    projection_fn,\n",
    "    step_size=0.01,    \n",
    "    shrink_towards='cluster_center',\n",
    "    loss_type='normal_loss',\n",
    "    force_refresh=True, \n",
    "    test_description=None,\n",
    "    output_root=None):\n",
    "    \"\"\"\n",
    "    Returns poisoned_X_train, a subset of model.data_sets.train (marked by indices_to_poison)\n",
    "    that has been modified by a single gradient step.\n",
    "    \"\"\"\n",
    "\n",
    "    data_sets = model.data_sets\n",
    "\n",
    "    if test_description is None:\n",
    "        test_description = test_idx\n",
    "    grad_filename = os.path.join(output_root, 'grad_influence_wrt_input_val_%s_testidx_%s.npy' % (model.model_name, test_description))\n",
    "\n",
    "    if (force_refresh == False) and (os.path.exists(grad_filename)):\n",
    "        grad_influence_wrt_input_val = np.load(grad_filename)\n",
    "    else:\n",
    "        grad_influence_wrt_input_val = model.get_grad_of_influence_wrt_input(\n",
    "            indices_to_poison, \n",
    "            test_idx, \n",
    "            verbose=False,\n",
    "            force_refresh=force_refresh,\n",
    "            test_description=test_description,\n",
    "            loss_type=loss_type)    \n",
    "\n",
    "    poisoned_X_train = data_sets.train.x[indices_to_poison, :]\n",
    "    poisoned_X_train -= step_size * grad_influence_wrt_input_val\n",
    "\n",
    "    poisoned_labels = data_sets.train.labels[indices_to_poison]        \n",
    "    poisoned_X_train = projection_fn(poisoned_X_train, poisoned_labels)\n",
    "\n",
    "    return poisoned_X_train \n",
    "\n",
    "\n",
    "def iterative_attack(\n",
    "    model, \n",
    "    indices_to_poison, \n",
    "    test_idx, \n",
    "    test_description=None,\n",
    "    step_size=0.01, \n",
    "    num_iter=10,\n",
    "    loss_type='normal_loss',\n",
    "    projection_fn=None,\n",
    "    output_root=None,\n",
    "    stop_after=3): \n",
    "\n",
    "    largest_test_loss = 0\n",
    "    stop_counter = 0\n",
    "\n",
    "    print('Test idx: %s' % test_idx)\n",
    "\n",
    "    np.save(os.path.join(output_root, '%s_indices' % model.model_name), indices_to_poison)\n",
    "    np.savez(os.path.join(output_root, '%s_x_iter-0' % (model.model_name)), \n",
    "        poisoned_X_train=model.data_sets.train.x, \n",
    "        Y_train=model.data_sets.train.labels)\n",
    "\n",
    "    for attack_iter in range(num_iter):\n",
    "        print('*** Iter: %s' % attack_iter)\n",
    "\n",
    "        # Create modified training dataset        \n",
    "        old_X_train = np.copy(model.data_sets.train.x)\n",
    "        poisoned_X_train_subset = poison_with_influence_proj_gradient_step(\n",
    "            model, \n",
    "            test_idx, \n",
    "            indices_to_poison,\n",
    "            projection_fn,\n",
    "            step_size=step_size,\n",
    "            loss_type=loss_type,\n",
    "            force_refresh=True, \n",
    "            test_description=test_description,\n",
    "            output_root=output_root)                \n",
    "     \n",
    "        poisoned_X_train = np.copy(model.data_sets.train.x)\n",
    "        poisoned_X_train[indices_to_poison, :] = poisoned_X_train_subset\n",
    "\n",
    "        # Measure some metrics on what the gradient step did\n",
    "        labels = model.data_sets.train.labels\n",
    "        dists_sum = 0.0\n",
    "        poisoned_dists_sum = 0.0\n",
    "        poisoned_mask = np.array([False] * len(labels), dtype=bool)\n",
    "        poisoned_mask[indices_to_poison] = True\n",
    "        for y in set(labels):\n",
    "            cluster_center = np.mean(poisoned_X_train[labels == y, :], axis=0)\n",
    "            dists = np.linalg.norm(poisoned_X_train[labels == y, :] - cluster_center, axis=1)\n",
    "            dists_sum += np.sum(dists)\n",
    "\n",
    "            poisoned_dists = np.linalg.norm(poisoned_X_train[(labels == y) & (poisoned_mask), :] - cluster_center, axis=1)\n",
    "            poisoned_dists_sum += np.sum(poisoned_dists)\n",
    "\n",
    "        dists_mean = dists_sum / len(labels)\n",
    "        poisoned_dists_mean = poisoned_dists_sum / len(indices_to_poison)\n",
    "\n",
    "        dists_moved = np.linalg.norm(old_X_train[indices_to_poison, :] - poisoned_X_train[indices_to_poison, :], axis=1)\n",
    "        print('Average distance to cluster center (overall): %s' % dists_mean)\n",
    "        print('Average distance to cluster center (poisoned): %s' % poisoned_dists_mean)\n",
    "        print('Average diff in X_train among poisoned indices = %s' % np.mean(dists_moved))\n",
    "        print('Fraction of 0 gradient points: %s' % np.mean(dists_moved == 0))\n",
    "        print('Average distance moved by points that moved: %s' % np.mean(dists_moved[dists_moved > 0]))\n",
    "        \n",
    "        # Update training dataset\n",
    "        model.update_train_x(poisoned_X_train)\n",
    "\n",
    "        # Retrain model\n",
    "        model.train()\n",
    "\n",
    "        if (attack_iter + 1) % 40 == 0:\n",
    "\n",
    "            # Calculate test loss\n",
    "            test_loss = model.sess.run(model.loss_no_reg, feed_dict=model.all_test_feed_dict)\n",
    "            if largest_test_loss < test_loss:\n",
    "                largest_test_loss = test_loss\n",
    "\n",
    "                np.savez(os.path.join(output_root, '%s_attack' % (model.model_name)), \n",
    "                    poisoned_X_train=poisoned_X_train, \n",
    "                    Y_train=model.data_sets.train.labels,\n",
    "                    attack_iter=attack_iter + 1)\n",
    "\n",
    "                stop_counter = 0\n",
    "            else:\n",
    "                stop_counter += 1\n",
    "\n",
    "            if stop_counter >= stop_after:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2212df39da21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0msphere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_sphere\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mslab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_slab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             percentile=70)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive/Adversarial ML/Experiments_code/data_utils.py\u001b[0m in \u001b[0;36mget_projection_fn\u001b[0;34m(X_clean, Y_clean, sphere, slab, percentile)\u001b[0m\n\u001b[1;32m    188\u001b[0m     percentile=70):\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mclass_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroid_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msphere_radii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslab_radii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msphere\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mslab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mprojector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupper_bounds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProjector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive/Adversarial ML/Experiments_code/data_utils.py\u001b[0m in \u001b[0;36mget_data_params\u001b[0;34m(X, Y, percentile)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mclass_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_class_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_centroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Get radii for sphere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive/Adversarial ML/Experiments_code/data_utils.py\u001b[0m in \u001b[0;36mget_centroids\u001b[0;34m(X, Y, class_map)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#Now that we have data_utils and the iterative_attack, we could replicate the code from gradient_attack.py\n",
    "\n",
    "#Configurations\n",
    "eps = 0.2\n",
    "step_size = 0.001\n",
    "random_seed = 9001\n",
    "project_sphere = True\n",
    "project_slab = True\n",
    "\n",
    "total_copies = int(np.round(eps*train_images.shape[0]))\n",
    "num_pos_copies = int(total_copies/2)\n",
    "num_neg_copies = total_copies - num_pos_copies\n",
    "\n",
    "# X_mod, Y_mod = data.copy_random_points(\n",
    "# train_images, train_labels,\n",
    "# target_class = 1,\n",
    "# num_copies = num_pos_copies,\n",
    "# random_seed = random_seed,\n",
    "# replace = True\n",
    "# )\n",
    "\n",
    "# X_mod, Y_mod = data.copy_random_points(\n",
    "# train_images, train_labels,\n",
    "# target_class = -1,\n",
    "# num_copies = num_neg_copies,\n",
    "# random_seed = random_seed,\n",
    "# replace = True\n",
    "# )\n",
    "\n",
    "#provide the influence function model using smoothHinge or whatever\n",
    "\n",
    "projection_fn = data.get_projection_fn(\n",
    "            train_images, train_labels,\n",
    "            sphere=project_sphere,\n",
    "            slab=project_slab,\n",
    "            percentile=70)\n",
    "\n",
    "\n",
    "iterative_attack(\n",
    "    model, \n",
    "    indices_to_poison=np.arange(X_train.shape[0], X_modified.shape[0]),            \n",
    "    test_idx=None, \n",
    "    test_description=None, \n",
    "    step_size=step_size, \n",
    "    num_iter=2000,\n",
    "    loss_type='normal_loss',\n",
    "    projection_fn=projection_fn,\n",
    "    output_root=output_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-hypothesis 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
