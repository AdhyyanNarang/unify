{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys\n",
    "import logging\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.16\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='results.log')\n",
    "\n",
    "logger = logging.getLogger('stab.gen.expt')\n",
    "handler = logging.FileHandler('results.log')\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.warning('Hey, it is good!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the MNIST dataset/ Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test the network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adv_util import create_fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_mnist(x):\n",
    "    n, img_rows, img_cols = x.shape\n",
    "    D = img_rows * img_cols\n",
    "    x_flattened = x.reshape(n, D)\n",
    "    return x_flattened, (D, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_both(model, x_test_flat, y_test, corrupt_func):\n",
    "    loss_benign, acc_benign = model.evaluate(x_test_flat, y_test, verbose=False)\n",
    "    x_test_corrupt = corrupt_data(x_test, x_test.shape[0], corrupt_func)\n",
    "    x_test_corrupt_flat, _ = flatten_mnist(x_test_corrupt)\n",
    "    loss_corrupt, acc_corrupt = model.evaluate(x_test_corrupt_flat, y_test, verbose=False)\n",
    "    return (loss_benign, acc_benign, loss_corrupt, acc_corrupt)                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_train_test(x_train, y_train, x_test, y_test, reg = 1e-3, corrupt_func = None, frac = 0.4):\n",
    "    \n",
    "    #Config\n",
    "    num_classes = 10\n",
    "    \n",
    "    x_train_flat, input_shape = flatten_mnist(x_train)\n",
    "    x_test_flat, _ = flatten_mnist(x_test)\n",
    "    \n",
    "    print(\"Frac value:\" + str(frac))\n",
    "    \n",
    "    \n",
    "    #Fit regular data\n",
    "    model = create_fully_connected(input_shape = input_shape, num_classes = num_classes, reg = reg)\n",
    "    model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train_flat, y_train, batch_size=128, epochs=15, verbose=True, validation_split=.1)\n",
    "    loss_benign, acc_benign, loss_corrupt, acc_corrupt = evaluate_on_both(model, x_test_flat, y_test, corrupt_func)\n",
    "    \n",
    "   \n",
    "    #Fit corrupted data\n",
    "    model = create_fully_connected(input_shape = input_shape, num_classes = num_classes, reg = reg)\n",
    "    model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    x_train_corrupt = corrupt_data(x_train, int(np.round(frac*x_train.shape[0])), corrupt_func)\n",
    "    x_train_corrupt_flat, _ = flatten_mnist(x_train_corrupt)\n",
    "    model.fit(x_train_corrupt_flat, y_train, batch_size=128, epochs=15, verbose=True, validation_split=.1)\n",
    "    \n",
    "    loss_benign_poison, acc_benign_poison, loss_corrupt_poison, acc_corrupt_poison = evaluate_on_both(model, x_test_flat, y_test, corrupt_func)\n",
    "    \n",
    "    \n",
    "    #Stab and generalization quantities\n",
    "    x_loss = loss_benign_poison - loss_benign\n",
    "    x_acc = acc_benign_poison - acc_benign\n",
    "    y_loss = loss_corrupt - loss_benign\n",
    "    y_acc = acc_corrupt - acc_benign\n",
    "    \n",
    "    logging.info('Reg: %s Corruption: %s Frac_corrupt: %s Stability_loss %s Stability_acc %s Gen_loss %s Gen_acc %s'\n",
    "                    % (reg, str(corrupt_func), frac, x_loss, x_acc, y_loss, y_acc))\n",
    "    \n",
    "    \n",
    "    return x_loss, x_acc, y_loss, y_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_corruption import gaussian_blurring, corrupt_data, random_perturbation, random_blackout_whiteout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_small = x_train[0:5]\n",
    "\n",
    "x_corrupted_small = corrupt_data(x_small, int(np.round(0.4 * x_small.shape[0])), random_perturbation)\n",
    "x_corrupted_reshaped = x_corrupted_small.reshape((x_corrupted_small.shape[0], 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14c9eb898>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_corrupted_small[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability and Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adv_util import create_fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac value:0.4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s - loss: 2.3174 - acc: 0.1465 - val_loss: 2.2753 - val_acc: 0.2632\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s - loss: 2.2628 - acc: 0.2193 - val_loss: 2.2468 - val_acc: 0.2967\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2321 - acc: 0.3134 - val_loss: 2.2114 - val_acc: 0.4338\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1932 - acc: 0.4188 - val_loss: 2.1660 - val_acc: 0.4877\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1421 - acc: 0.4839 - val_loss: 2.1059 - val_acc: 0.5322\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.0757 - acc: 0.5238 - val_loss: 2.0291 - val_acc: 0.5733\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.9923 - acc: 0.5538 - val_loss: 1.9350 - val_acc: 0.6048\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.8943 - acc: 0.5813 - val_loss: 1.8274 - val_acc: 0.6148\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.7860 - acc: 0.6011 - val_loss: 1.7119 - val_acc: 0.6442\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.6731 - acc: 0.6175 - val_loss: 1.5938 - val_acc: 0.6562\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.5612 - acc: 0.6425 - val_loss: 1.4791 - val_acc: 0.6650\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.4547 - acc: 0.6567 - val_loss: 1.3719 - val_acc: 0.7090\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.3560 - acc: 0.6848 - val_loss: 1.2729 - val_acc: 0.7260\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.2659 - acc: 0.7018 - val_loss: 1.1829 - val_acc: 0.7540\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.1840 - acc: 0.7231 - val_loss: 1.1013 - val_acc: 0.7620\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 2.3207 - acc: 0.1408 - val_loss: 2.2799 - val_acc: 0.1940\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2699 - acc: 0.1831 - val_loss: 2.2567 - val_acc: 0.3112\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2452 - acc: 0.2774 - val_loss: 2.2291 - val_acc: 0.3735\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2147 - acc: 0.3733 - val_loss: 2.1940 - val_acc: 0.4160\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1753 - acc: 0.4310 - val_loss: 2.1481 - val_acc: 0.4578\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1241 - acc: 0.4819 - val_loss: 2.0889 - val_acc: 0.4975\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.0586 - acc: 0.5093 - val_loss: 2.0139 - val_acc: 0.5613\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.9784 - acc: 0.5379 - val_loss: 1.9244 - val_acc: 0.5852\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.8859 - acc: 0.5625 - val_loss: 1.8239 - val_acc: 0.6043\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.7852 - acc: 0.5866 - val_loss: 1.7164 - val_acc: 0.6223\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.6809 - acc: 0.6038 - val_loss: 1.6073 - val_acc: 0.6453\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.5776 - acc: 0.6280 - val_loss: 1.5013 - val_acc: 0.6623\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.4791 - acc: 0.6458 - val_loss: 1.4016 - val_acc: 0.6855\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.3873 - acc: 0.6666 - val_loss: 1.3091 - val_acc: 0.7038\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.3029 - acc: 0.6839 - val_loss: 1.2245 - val_acc: 0.7258\n",
      "Frac value:0.4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 2.3273 - acc: 0.1465 - val_loss: 2.2852 - val_acc: 0.2632\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2728 - acc: 0.2186 - val_loss: 2.2570 - val_acc: 0.2943\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2425 - acc: 0.3117 - val_loss: 2.2221 - val_acc: 0.4323\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2043 - acc: 0.4169 - val_loss: 2.1775 - val_acc: 0.4873\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1542 - acc: 0.4825 - val_loss: 2.1187 - val_acc: 0.5307\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.0892 - acc: 0.5224 - val_loss: 2.0435 - val_acc: 0.5727\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.0076 - acc: 0.5523 - val_loss: 1.9514 - val_acc: 0.6027\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.9115 - acc: 0.5792 - val_loss: 1.8460 - val_acc: 0.6133\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.8053 - acc: 0.5988 - val_loss: 1.7326 - val_acc: 0.6430\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.6944 - acc: 0.6149 - val_loss: 1.6164 - val_acc: 0.6530\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.5842 - acc: 0.6406 - val_loss: 1.5035 - val_acc: 0.6628\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.4793 - acc: 0.6540 - val_loss: 1.3978 - val_acc: 0.7063\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.3821 - acc: 0.6819 - val_loss: 1.3002 - val_acc: 0.7228\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.2932 - acc: 0.6983 - val_loss: 1.2114 - val_acc: 0.7528\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.2125 - acc: 0.7203 - val_loss: 1.1309 - val_acc: 0.7595\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 2.3306 - acc: 0.1408 - val_loss: 2.2899 - val_acc: 0.1938\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2799 - acc: 0.1828 - val_loss: 2.2669 - val_acc: 0.3108\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2556 - acc: 0.2764 - val_loss: 2.2397 - val_acc: 0.3715\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2256 - acc: 0.3715 - val_loss: 2.2052 - val_acc: 0.4142\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1870 - acc: 0.4295 - val_loss: 2.1603 - val_acc: 0.4568\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1369 - acc: 0.4805 - val_loss: 2.1025 - val_acc: 0.4948\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.0730 - acc: 0.5074 - val_loss: 2.0292 - val_acc: 0.5597\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.9945 - acc: 0.5360 - val_loss: 1.9417 - val_acc: 0.5837\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.9040 - acc: 0.5605 - val_loss: 1.8433 - val_acc: 0.6017\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.8053 - acc: 0.5848 - val_loss: 1.7380 - val_acc: 0.6213\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.7030 - acc: 0.6016 - val_loss: 1.6307 - val_acc: 0.6443\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.6014 - acc: 0.6252 - val_loss: 1.5264 - val_acc: 0.6597\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.5044 - acc: 0.6431 - val_loss: 1.4281 - val_acc: 0.6815\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.4140 - acc: 0.6641 - val_loss: 1.3370 - val_acc: 0.6997\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.3308 - acc: 0.6810 - val_loss: 1.2536 - val_acc: 0.7233\n",
      "Frac value:0.4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 0s - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2860 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2667 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 2.4288 - acc: 0.1404 - val_loss: 2.3877 - val_acc: 0.1908\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3777 - acc: 0.1783 - val_loss: 2.3651 - val_acc: 0.3037\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3546 - acc: 0.2649 - val_loss: 2.3402 - val_acc: 0.3607\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3279 - acc: 0.3563 - val_loss: 2.3103 - val_acc: 0.3915\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2952 - acc: 0.4112 - val_loss: 2.2730 - val_acc: 0.4400\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2542 - acc: 0.4639 - val_loss: 2.2263 - val_acc: 0.4728\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.2028 - acc: 0.4879 - val_loss: 2.1678 - val_acc: 0.5393\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.1399 - acc: 0.5170 - val_loss: 2.0975 - val_acc: 0.5598\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.0667 - acc: 0.5395 - val_loss: 2.0176 - val_acc: 0.5770\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.9856 - acc: 0.5630 - val_loss: 1.9306 - val_acc: 0.6003\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.9003 - acc: 0.5794 - val_loss: 1.8403 - val_acc: 0.6192\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.8139 - acc: 0.5976 - val_loss: 1.7507 - val_acc: 0.6352\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.7300 - acc: 0.6174 - val_loss: 1.6650 - val_acc: 0.6537\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.6510 - acc: 0.6348 - val_loss: 1.5851 - val_acc: 0.6667\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 1.5781 - acc: 0.6513 - val_loss: 1.5119 - val_acc: 0.6880\n",
      "Frac value:0.4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 3.3303 - acc: 0.1404 - val_loss: 3.2109 - val_acc: 0.2192\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 3.1340 - acc: 0.1558 - val_loss: 3.0607 - val_acc: 0.1642\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.9982 - acc: 0.1740 - val_loss: 2.9378 - val_acc: 0.2095\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.8867 - acc: 0.1979 - val_loss: 2.8368 - val_acc: 0.2718\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.7943 - acc: 0.2389 - val_loss: 2.7525 - val_acc: 0.2643\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.7174 - acc: 0.2504 - val_loss: 2.6824 - val_acc: 0.2805\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.6530 - acc: 0.2601 - val_loss: 2.6234 - val_acc: 0.2848\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.5988 - acc: 0.2816 - val_loss: 2.5740 - val_acc: 0.2440\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.5528 - acc: 0.2687 - val_loss: 2.5319 - val_acc: 0.3075\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.5137 - acc: 0.2931 - val_loss: 2.4961 - val_acc: 0.2805\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4802 - acc: 0.2799 - val_loss: 2.4650 - val_acc: 0.2990\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4511 - acc: 0.2912 - val_loss: 2.4383 - val_acc: 0.3000\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4256 - acc: 0.2878 - val_loss: 2.4141 - val_acc: 0.2928\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4027 - acc: 0.2875 - val_loss: 2.3926 - val_acc: 0.2942\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3819 - acc: 0.2897 - val_loss: 2.3730 - val_acc: 0.2688\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 3.3331 - acc: 0.1354 - val_loss: 3.2139 - val_acc: 0.1640\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 3.1377 - acc: 0.1403 - val_loss: 3.0648 - val_acc: 0.2207\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 3.0027 - acc: 0.1621 - val_loss: 2.9429 - val_acc: 0.1888\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.8915 - acc: 0.1812 - val_loss: 2.8421 - val_acc: 0.1412\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.7992 - acc: 0.1756 - val_loss: 2.7582 - val_acc: 0.2082\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.7224 - acc: 0.2095 - val_loss: 2.6884 - val_acc: 0.1655\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.6582 - acc: 0.1912 - val_loss: 2.6295 - val_acc: 0.2537\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.6042 - acc: 0.2170 - val_loss: 2.5802 - val_acc: 0.2692\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.5589 - acc: 0.2285 - val_loss: 2.5389 - val_acc: 0.2672\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.5206 - acc: 0.2405 - val_loss: 2.5038 - val_acc: 0.2243\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4881 - acc: 0.2328 - val_loss: 2.4736 - val_acc: 0.2817\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4605 - acc: 0.2477 - val_loss: 2.4485 - val_acc: 0.2302\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4369 - acc: 0.2464 - val_loss: 2.4268 - val_acc: 0.2455\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4166 - acc: 0.2387 - val_loss: 2.4083 - val_acc: 0.2432\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3991 - acc: 0.2433 - val_loss: 2.3919 - val_acc: 0.2693\n",
      "Frac value:0.4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 7.6425 - acc: 0.1031 - val_loss: 4.3310 - val_acc: 0.1050\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 3.2836 - acc: 0.1132 - val_loss: 2.6776 - val_acc: 0.1050\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4831 - acc: 0.1132 - val_loss: 2.3715 - val_acc: 0.1050\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3350 - acc: 0.1132 - val_loss: 2.3151 - val_acc: 0.1050\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3076 - acc: 0.1132 - val_loss: 2.3044 - val_acc: 0.1050\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3026 - acc: 0.1132 - val_loss: 2.3025 - val_acc: 0.1050\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3016 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3015 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 7.6436 - acc: 0.1017 - val_loss: 4.3307 - val_acc: 0.1050\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 3.2834 - acc: 0.1132 - val_loss: 2.6771 - val_acc: 0.1050\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.4830 - acc: 0.1132 - val_loss: 2.3716 - val_acc: 0.1050\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3350 - acc: 0.1132 - val_loss: 2.3152 - val_acc: 0.1050\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3076 - acc: 0.1132 - val_loss: 2.3047 - val_acc: 0.1050\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3025 - acc: 0.1132 - val_loss: 2.3030 - val_acc: 0.1050\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3016 - acc: 0.1132 - val_loss: 2.3024 - val_acc: 0.1050\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3024 - val_acc: 0.1050\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3019 - val_acc: 0.1050\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Frac value:0.4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 8.9084 - acc: 0.1076 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3016 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3019 - val_acc: 0.1050\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3019 - val_acc: 0.1050\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3012 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 8.9089 - acc: 0.1066 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3016 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3012 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3012 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Frac value:0.4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 9.5701 - acc: 0.1116 - val_loss: 2.3024 - val_acc: 0.1050\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3017 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3015 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s - loss: 9.5703 - acc: 0.1113 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3017 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3014 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3022 - val_acc: 0.1050\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3023 - val_acc: 0.1050\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3021 - val_acc: 0.1050\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3020 - val_acc: 0.1050\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 0s - loss: 2.3013 - acc: 0.1132 - val_loss: 2.3023 - val_acc: 0.1050\n"
     ]
    }
   ],
   "source": [
    "reg_array = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10]\n",
    "diff_loss_lst = []\n",
    "diff_acc_lst = []\n",
    "acc_corrupt_lst = []\n",
    "loss_corrupt_lst =[]\n",
    "\n",
    "for reg in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10]:\n",
    "    diff_loss, diff_acc, loss_test_corrupt, accuracy_test_corrupt = compile_train_test(x_train, y_train, x_test, y_test, reg = reg, corrupt_func = random_blackout_whiteout)\n",
    "    diff_loss_lst.append(diff_loss)\n",
    "    diff_acc_lst.append(diff_acc)\n",
    "    acc_corrupt_lst.append(accuracy_test_corrupt)\n",
    "    loss_corrupt_lst.append(loss_test_corrupt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff_loss_lst = [np.abs(x) for x in diff_loss_lst]\n",
    "loss_corrupt_lst = [np.abs(x) for x in loss_corrupt_lst]\n",
    "\n",
    "plt.scatter(diff_loss_lst, loss_corrupt_lst)\n",
    "plt.xlabel('Poisoning Loss - Test loss')\n",
    "plt.ylabel('Corruption Test Loss - Test Loss')\n",
    "\n",
    "\n",
    "plt.xlabel('Stability proxy')\n",
    "plt.ylabel('Generalization proxy')\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "\"\"\"\n",
    "for k in range(len(reg_array)):\n",
    "    reg_val = reg_array[k]\n",
    "    x = diff_loss_lst[k]\n",
    "    y = loss_corrupt_lst[k]\n",
    "    plt.annotate(reg_val, xy=(x, y), xytext=(-0.5, 0.5), textcoords='offset points', ha='right', va='bottom')\n",
    "\"\"\"    \n",
    "\n",
    "plt.savefig('images/reg_new/random_blackwhite_loss_new.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff_acc_lst = [np.abs(x) for x in diff_acc_lst]\n",
    "acc_corrupt_lst = [np.abs(x) for x in acc_corrupt_lst]\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.scatter(diff_acc_lst, acc_corrupt_lst)\n",
    "plt.xlabel('Stability proxy')\n",
    "plt.ylabel('Generalization proxy')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "for k in range(len(reg_array)):\n",
    "    reg_val = reg_array[k]\n",
    "    x = diff_acc_lst[k]\n",
    "    y = acc_corrupt_lst[k]\n",
    "    plt.annotate(reg_val, xy=(x, y), xytext=(-20, 20), textcoords='offset points', ha='right', va='bottom')\n",
    "\"\"\"\n",
    "\n",
    "plt.savefig('random_blackwhite_acc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does benign test loss scale with fraction of training set corrupted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac value:0.1\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 2.4260 - acc: 0.1347 - val_loss: 2.3846 - val_acc: 0.2063\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3729 - acc: 0.2046 - val_loss: 2.3583 - val_acc: 0.2345\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3459 - acc: 0.2929 - val_loss: 2.3284 - val_acc: 0.3523\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3140 - acc: 0.3805 - val_loss: 2.2922 - val_acc: 0.4773\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2744 - acc: 0.4535 - val_loss: 2.2470 - val_acc: 0.5117\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2243 - acc: 0.4976 - val_loss: 2.1891 - val_acc: 0.5340\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1618 - acc: 0.5207 - val_loss: 2.1185 - val_acc: 0.5725\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.0871 - acc: 0.5518 - val_loss: 2.0354 - val_acc: 0.5813\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.0027 - acc: 0.5721 - val_loss: 1.9446 - val_acc: 0.6037\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 1.9124 - acc: 0.5885 - val_loss: 1.8483 - val_acc: 0.6253\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8202 - acc: 0.6103 - val_loss: 1.7525 - val_acc: 0.6413\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 1.7300 - acc: 0.6263 - val_loss: 1.6599 - val_acc: 0.6603\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 1.6451 - acc: 0.6426 - val_loss: 1.5744 - val_acc: 0.6832\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 1.5668 - acc: 0.6605 - val_loss: 1.4960 - val_acc: 0.7080\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.4955 - acc: 0.6822 - val_loss: 1.4238 - val_acc: 0.7110\n",
      "Frac value:0.2\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 2.4266 - acc: 0.1348 - val_loss: 2.3857 - val_acc: 0.1577\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3745 - acc: 0.2006 - val_loss: 2.3611 - val_acc: 0.2090\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3490 - acc: 0.2751 - val_loss: 2.3323 - val_acc: 0.3758\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3188 - acc: 0.3746 - val_loss: 2.2987 - val_acc: 0.4480\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.2818 - acc: 0.4401 - val_loss: 2.2559 - val_acc: 0.5068\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2349 - acc: 0.4857 - val_loss: 2.2018 - val_acc: 0.5295\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.1763 - acc: 0.5143 - val_loss: 2.1354 - val_acc: 0.5583\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.1057 - acc: 0.5384 - val_loss: 2.0571 - val_acc: 0.5740\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0249 - acc: 0.5545 - val_loss: 1.9694 - val_acc: 0.6070\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.9377 - acc: 0.5792 - val_loss: 1.8765 - val_acc: 0.6100\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8476 - acc: 0.5977 - val_loss: 1.7822 - val_acc: 0.6288\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7585 - acc: 0.6141 - val_loss: 1.6912 - val_acc: 0.6580\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.6737 - acc: 0.6360 - val_loss: 1.6050 - val_acc: 0.6588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.5952 - acc: 0.6501 - val_loss: 1.5261 - val_acc: 0.6882\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.5234 - acc: 0.6697 - val_loss: 1.4543 - val_acc: 0.7118\n",
      "Frac value:0.30000000000000004\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 2.4270 - acc: 0.1360 - val_loss: 2.3866 - val_acc: 0.1755\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3762 - acc: 0.1920 - val_loss: 2.3634 - val_acc: 0.1985\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3519 - acc: 0.2545 - val_loss: 2.3366 - val_acc: 0.4088\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3235 - acc: 0.3711 - val_loss: 2.3047 - val_acc: 0.4280\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2887 - acc: 0.4274 - val_loss: 2.2651 - val_acc: 0.4800\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2449 - acc: 0.4722 - val_loss: 2.2147 - val_acc: 0.5235\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.1900 - acc: 0.5033 - val_loss: 2.1524 - val_acc: 0.5410\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.1233 - acc: 0.5281 - val_loss: 2.0781 - val_acc: 0.5685\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0462 - acc: 0.5498 - val_loss: 1.9939 - val_acc: 0.5932\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.9619 - acc: 0.5710 - val_loss: 1.9043 - val_acc: 0.6028\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.8741 - acc: 0.5892 - val_loss: 1.8119 - val_acc: 0.6273\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7862 - acc: 0.6103 - val_loss: 1.7209 - val_acc: 0.6378\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7018 - acc: 0.6259 - val_loss: 1.6354 - val_acc: 0.6598\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.6231 - acc: 0.6426 - val_loss: 1.5560 - val_acc: 0.6797\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.5509 - acc: 0.6596 - val_loss: 1.4835 - val_acc: 0.7043\n",
      "Frac value:0.4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 42us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 2.4288 - acc: 0.1404 - val_loss: 2.3877 - val_acc: 0.1908\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3777 - acc: 0.1783 - val_loss: 2.3651 - val_acc: 0.3037\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3546 - acc: 0.2649 - val_loss: 2.3402 - val_acc: 0.3607\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3279 - acc: 0.3563 - val_loss: 2.3103 - val_acc: 0.3915\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2952 - acc: 0.4112 - val_loss: 2.2730 - val_acc: 0.4400\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2542 - acc: 0.4639 - val_loss: 2.2263 - val_acc: 0.4728\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2028 - acc: 0.4879 - val_loss: 2.1678 - val_acc: 0.5393\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1399 - acc: 0.5170 - val_loss: 2.0975 - val_acc: 0.5598\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0667 - acc: 0.5395 - val_loss: 2.0176 - val_acc: 0.5770\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.9856 - acc: 0.5630 - val_loss: 1.9306 - val_acc: 0.6003\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.9003 - acc: 0.5794 - val_loss: 1.8403 - val_acc: 0.6192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8139 - acc: 0.5976 - val_loss: 1.7507 - val_acc: 0.6352\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7300 - acc: 0.6174 - val_loss: 1.6650 - val_acc: 0.6537\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.6510 - acc: 0.6348 - val_loss: 1.5851 - val_acc: 0.6667\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.5781 - acc: 0.6513 - val_loss: 1.5119 - val_acc: 0.6880\n",
      "Frac value:0.5\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 43us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 3s 54us/step - loss: 2.4279 - acc: 0.1314 - val_loss: 2.3894 - val_acc: 0.1570\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.3792 - acc: 0.1856 - val_loss: 2.3683 - val_acc: 0.1522\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 2.3574 - acc: 0.2352 - val_loss: 2.3435 - val_acc: 0.3083\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.3321 - acc: 0.3435 - val_loss: 2.3153 - val_acc: 0.3448\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.3016 - acc: 0.3952 - val_loss: 2.2805 - val_acc: 0.4682\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.2634 - acc: 0.4518 - val_loss: 2.2371 - val_acc: 0.4897\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.2154 - acc: 0.4872 - val_loss: 2.1825 - val_acc: 0.5147\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.1564 - acc: 0.5115 - val_loss: 2.1163 - val_acc: 0.5382\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 2.0868 - acc: 0.5313 - val_loss: 2.0397 - val_acc: 0.5732\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 2.0091 - acc: 0.5430 - val_loss: 1.9561 - val_acc: 0.5880\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 1.9263 - acc: 0.5728 - val_loss: 1.8683 - val_acc: 0.5968\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.8418 - acc: 0.5869 - val_loss: 1.7804 - val_acc: 0.6248\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.7587 - acc: 0.6097 - val_loss: 1.6949 - val_acc: 0.6343\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 1.6797 - acc: 0.6265 - val_loss: 1.6144 - val_acc: 0.6527\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 1.6065 - acc: 0.6421 - val_loss: 1.5406 - val_acc: 0.6665\n",
      "Frac value:0.6\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 2.4279 - acc: 0.1316 - val_loss: 2.3904 - val_acc: 0.1610\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3807 - acc: 0.1772 - val_loss: 2.3700 - val_acc: 0.1688\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3600 - acc: 0.2321 - val_loss: 2.3475 - val_acc: 0.2905\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3362 - acc: 0.3198 - val_loss: 2.3211 - val_acc: 0.3957\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3076 - acc: 0.3979 - val_loss: 2.2885 - val_acc: 0.4213\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2720 - acc: 0.4376 - val_loss: 2.2478 - val_acc: 0.4647\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2274 - acc: 0.4755 - val_loss: 2.1968 - val_acc: 0.5005\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.1720 - acc: 0.4992 - val_loss: 2.1348 - val_acc: 0.5315\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.1061 - acc: 0.5259 - val_loss: 2.0626 - val_acc: 0.5313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0315 - acc: 0.5354 - val_loss: 1.9817 - val_acc: 0.5768\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 1.9513 - acc: 0.5601 - val_loss: 1.8963 - val_acc: 0.5965\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8685 - acc: 0.5805 - val_loss: 1.8096 - val_acc: 0.6115\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7861 - acc: 0.5954 - val_loss: 1.7249 - val_acc: 0.6332\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7073 - acc: 0.6181 - val_loss: 1.6449 - val_acc: 0.6430\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 1.6336 - acc: 0.6336 - val_loss: 1.5704 - val_acc: 0.6638\n",
      "Frac value:0.7000000000000001\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 2.4294 - acc: 0.1193 - val_loss: 2.3912 - val_acc: 0.1683\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3821 - acc: 0.1752 - val_loss: 2.3724 - val_acc: 0.1617\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3625 - acc: 0.2304 - val_loss: 2.3510 - val_acc: 0.2368\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3401 - acc: 0.2932 - val_loss: 2.3261 - val_acc: 0.3815\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.3134 - acc: 0.3821 - val_loss: 2.2955 - val_acc: 0.3945\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2803 - acc: 0.4157 - val_loss: 2.2577 - val_acc: 0.4958\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2386 - acc: 0.4722 - val_loss: 2.2100 - val_acc: 0.4780\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.1869 - acc: 0.4888 - val_loss: 2.1518 - val_acc: 0.5058\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.1248 - acc: 0.5103 - val_loss: 2.0825 - val_acc: 0.5463\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.0535 - acc: 0.5325 - val_loss: 2.0049 - val_acc: 0.5565\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 1.9758 - acc: 0.5457 - val_loss: 1.9221 - val_acc: 0.5910\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.8949 - acc: 0.5712 - val_loss: 1.8369 - val_acc: 0.6053\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 1.8136 - acc: 0.5894 - val_loss: 1.7532 - val_acc: 0.6187\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 1.7349 - acc: 0.6045 - val_loss: 1.6727 - val_acc: 0.6402\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 1.6610 - acc: 0.6262 - val_loss: 1.5975 - val_acc: 0.6495\n",
      "Frac value:0.8\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 4s 70us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 24us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 25us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2860 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 24us/step - loss: 2.2667 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 2.1466 - acc: 0.5365 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 24us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 24us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 3s 55us/step - loss: 2.4292 - acc: 0.1251 - val_loss: 2.3928 - val_acc: 0.1370\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.3836 - acc: 0.1637 - val_loss: 2.3743 - val_acc: 0.1830\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 2.3650 - acc: 0.2241 - val_loss: 2.3539 - val_acc: 0.2498\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 25us/step - loss: 2.3440 - acc: 0.2883 - val_loss: 2.3305 - val_acc: 0.3657\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 2.3190 - acc: 0.3549 - val_loss: 2.3022 - val_acc: 0.4392\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2883 - acc: 0.4229 - val_loss: 2.2671 - val_acc: 0.4417\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.2498 - acc: 0.4460 - val_loss: 2.2236 - val_acc: 0.5020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2017 - acc: 0.4784 - val_loss: 2.1685 - val_acc: 0.5285\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.1434 - acc: 0.5035 - val_loss: 2.1037 - val_acc: 0.5410\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.0757 - acc: 0.5237 - val_loss: 2.0297 - val_acc: 0.5540\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.0010 - acc: 0.5399 - val_loss: 1.9495 - val_acc: 0.5858\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 1.9222 - acc: 0.5597 - val_loss: 1.8662 - val_acc: 0.5977\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8422 - acc: 0.5799 - val_loss: 1.7832 - val_acc: 0.6150\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.7638 - acc: 0.5969 - val_loss: 1.7029 - val_acc: 0.6302\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 1.6895 - acc: 0.6135 - val_loss: 1.6272 - val_acc: 0.6487\n",
      "Frac value:0.9\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 2.4300 - acc: 0.1218 - val_loss: 2.3940 - val_acc: 0.1802\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.3849 - acc: 0.1636 - val_loss: 2.3759 - val_acc: 0.2138\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3673 - acc: 0.2140 - val_loss: 2.3570 - val_acc: 0.2613\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.3476 - acc: 0.2906 - val_loss: 2.3354 - val_acc: 0.2940\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.3243 - acc: 0.3347 - val_loss: 2.3091 - val_acc: 0.4592\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.2958 - acc: 0.4066 - val_loss: 2.2767 - val_acc: 0.4750\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2601 - acc: 0.4472 - val_loss: 2.2356 - val_acc: 0.4615\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2155 - acc: 0.4654 - val_loss: 2.1855 - val_acc: 0.5103\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1609 - acc: 0.4983 - val_loss: 2.1243 - val_acc: 0.5182\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0967 - acc: 0.5136 - val_loss: 2.0539 - val_acc: 0.5365\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0250 - acc: 0.5287 - val_loss: 1.9770 - val_acc: 0.5708\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.9485 - acc: 0.5530 - val_loss: 1.8955 - val_acc: 0.5775\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8701 - acc: 0.5648 - val_loss: 1.8134 - val_acc: 0.6095\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7924 - acc: 0.5882 - val_loss: 1.7334 - val_acc: 0.6138\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7179 - acc: 0.6046 - val_loss: 1.6574 - val_acc: 0.6345\n"
     ]
    }
   ],
   "source": [
    "frac_array = np.arange(0.1, 1.0, 0.1)\n",
    "loss_benign_poison_lst, acc_benign_poison_lst, loss_corrupt_poison_lst, acc_corrupt_poison_lst = [], [], [], []\n",
    "\n",
    "for frac in frac_array:\n",
    "    loss_benign_poison, acc_benign_poison, loss_corrupt_poison, acc_corrupt_poison = compile_train_test(x_train, y_train, x_test, y_test, corrupt_func = random_blackout_whiteout, frac = frac)\n",
    "    loss_benign_poison_lst.append(loss_benign_poison)\n",
    "    acc_benign_poison_lst.append(acc_benign_poison)\n",
    "    loss_corrupt_poison_lst.append(loss_corrupt_poison)\n",
    "    acc_corrupt_poison_lst.append(acc_corrupt_poison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYXFWZx/Hvz9CQ1kEaSAskCGEwRlk00QYHcZyAYpABDBhZHBUcNOIgzKIRMsMAgxsQRhAREAWDywQEQ0ANRpAljAraoUMSlsgu6TAkLCEsjSbhnT/uKax0qqtup6q6urp/n+epp+8999xbb1Ul9da9555zFBGYmZltqtc0OgAzM2tuTiRmZlYVJxIzM6uKE4mZmVXFicTMzKriRGJmZlVxIjEzs6o4kZiZWVWcSMzMrCqbNTqAgTBq1KgYO3Zso8MwM2sqCxcufCoi2ivVGxaJZOzYsXR2djY6DDOzpiLpsTz1fGnLzMyq4kRiZmZVcSIxM7OqOJGYmVlVnEjMzKwqTiRmZlYVJxIzM6uKE4mZmVXFicTMzKriRGJmZlVxIjEzs6o4kZiZWVXqmkgkXS5ppaSlZepMkrRI0j2SbisqP1DSMkkPSjqlqHwXSXdKekDSVZI2r+drMDOz8up9RjILOLCvjZLagIuAQyNid+AjqXwE8C3gg8BuwNGSdku7nQ2cFxHjgGeB4+oWvZmZVVTXRBIRC4BnylT5KDAnIv6Y6q9M5XsDD0bEwxHxZ+BK4EOSBOwPXJPqXQFMqUvwZmaWS6PbSN4MbC3pVkkLJX0ilY8BHi+qtzyVbQusjoh1vcrNzKxBGj2x1WbAO4H3Aa3AbyXdAahE3ShTvhFJ04BpADvttFNNgjUzs401+oxkOfCLiHgxIp4CFgBvT+VvLKq3I7ACeApok7RZr/KNRMSlEdERER3t7RVnijQzs03U6ERyHfC3kjaT9FrgXcB9wO+BcekOrc2Bo4DrIyKAW4Cpaf9j0jHMzKxB6nppS9JsYBIwStJy4HSgBSAiLomI+yT9AlgMvAJ8NyKWpn0/B8wHRgCXR8Q96bAnA1dK+jLQBVxWz9dgZmblKfuRP7R1dHREZ2dno8MwM6ubuV3dzJy/jBWrexjd1sr0yeOZMrG6e5EkLYyIjkr1Gt3YbmZmVZrb1c2MOUvoWbsegO7VPcyYswSg6mSSR6PbSMzMrEoz5y97NYkU9Kxdz8z5ywbk+Z1IzMya3IrVPf0qrzUnEjOzJje6rbVf5bXmRGJm1uSmTx5Pa8uIDcpaW0YwffL4AXl+N7abmTW5QoN6re/aysuJxMxsCJgyccyAJY7efGnLzMyq4kRiZmZVcSIxM7OqOJGYmVlVnEjMzKwqTiRmZlaViolE0kckbZmWT5U0R9I76h+amZk1gzxnJP8ZEc9Leg8wGbgCuLi+YZmZWbPIk0gKQ0r+PXBxRFwHbF6/kMzMrJnkSSTdkr4NHAHMk7RFzv3MzGwYyJMQjiCb8vbAiFgNbANMr7STpMslrZS0tI/tkyQ9J2lRepyWyscXlS2StEbSv6RtZ0jqLtp2UO5XamZmdVFxrK2IeEnSSuA9wAPAuvS3klnAhcD3y9S5PSIO7vV8y4AJAJJGAN3AtUVVzouIc3M8v5mZDYA8d22dDpwMzEhFLcAPK+0XEQuAZ6qKDt4HPBQRj1V5HDMzq5M8l7YOAw4FXgSIiBXAljV6/n0k3S3pBkm7l9h+FDC7V9nnJC1Ol862rlEcZma2ifIkkj9HRAABIOl1NXruu4CdI+LtwDeBucUbJW1OlsCuLiq+GNiV7NLXE8B/93VwSdMkdUrqXLVqVY1CNjOz3vIkkh+nu7baJH0auAn4TrVPHBFrIuKFtDwPaJE0qqjKB4G7IuLJon2ejIj1EfFKimHvMse/NCI6IqKjvb292nDNzF41t6ubfc+6mV1O+Tn7nnUzc7u6Gx1SQ+VpbD9X0gHAGmA8cFpE3FjtE0vaHngyIkLS3mRJ7emiKkfT67KWpB0i4om0ehhQ8o4wM7N6mdvVzYw5S+hZm3Wx617dw4w5SwAaNrFUo+WaITEljn4lD0mzgUnAKEnLgdPJGuqJiEuAqcBnJa0DeoCj0iU0JL0WOAD4TK/DniNpAtlltkdLbDczq6uZ85e9mkQKetauZ+b8ZU4kvUl6ntQu0nsTEBHx+nIHjoijK2y/kOz24FLbXgK2LVH+8XLHNDOrtxWre/pVPhz0mUgiolZ3ZpmZDRmj21rpLpE0Rre1NiCawSHXUCeS3iHpJEknSppY76DMzAar6ZPH09oyYoOy1pYRTJ88vkERNV6eDomnkY34uy0wCpgl6dR6B2ZmNhhNmTiGrx2+J2PaWhEwpq2Vrx2+57BtHwFQat/uu4J0HzAxIl5O661kt+W+dQDiq4mOjo7o7OxsdBhmZk1F0sKI6KhUL8+lrUeBkUXrWwAPbWJcZmY2xOS5/fdPwD2SbiS7i+sA4H8lXQAQESfVMT4zMxvk8iSSa9lw9N1b6xOKmZk1ozw9268YiEDMzKw55blr62BJXZKeSZNMPS9pzUAEZ2Zmg1+eS1vnA4cDS6LSLV5mZjbs5Llr63FgqZOImZmVkueM5IvAPEm3kd3BBUBEfL1uUZmZWdPIk0i+ArxA1pdk8/qGY2ZmzSZPItkmIj5Q90jMzKwp5WkjuUmSE4mZmZWUJ5GcAPxCUo9v/zUzs97ydEj0vCRmZtanXFPtStoaGEfR4I0RsaDCPpcDBwMrI2KPEtsnAdcBj6SiORFxZtr2KPA8sB5YVxh9UtI2wFXAWLLBJI+IiGfzvAYzM6uPPD3bPwUsAOYD/5X+npHj2LOAAyvUuT0iJqTHmb227ZfKi4cwPgX4VUSMA36V1s3MrIHytJH8M7AX8FhE7AdMBFZV2imdsTxTXXgb+RDZJFukv1NqfHwzG2TmdnWz71k3s8spP2ffs25mbld3o0OyXvIkkpeLJrXaIiLuB2o1p+Q+ku6WdIOk3YvKA/ilpIWSphWVbxcRTwCkv2+oURxmNgjN7epmxpwldK/uIYDu1T3MmLPEyWSQyZNIlktqA+YCN0q6DlhRg+e+C9g5It4OfDMdv2DfiHgH8EHgBEnv7e/BJU2T1Cmpc9WqiidQZjYIzZy/jJ616zco61m7npnzlzUoIiulYiKJiMMiYnVEnAH8J3AZNbikFBFrIuKFtDwPaJE0Kq2vSH9Xks2Fsnfa7UlJOwCkvyvLHP/SiOiIiI729vZqwzWzBlixuqdf5dYYeRrb319YjojbIuJ64Ohqn1jS9pKUlvdOsTwt6XWStkzlrwM+ACxNu10PHJOWjyG768vMhqjRba39KrfGyHNp6zRJF6cv+O0k/RQ4pNJOkmYDvwXGS1ou6ThJx0s6PlWZCiyVdDdwAXBUGmF4O7KpfO8Gfgf8PCJ+kfY5CzhA0gNkU/6e1Z8Xa2bNZfrk8bS2jNigrLVlBNMn16qZ1mpBlUaHT2cNnwc+k4pOi4jZ9Q6sljo6OqKzs7PRYZjZJpjb1c3M+ctYsbqH0W2tTJ88nikTxzQ6rGFB0sJeXTBKytMhcWvgXcBDwI7AzpLk+UnMbCBMmTjGiWOQy3Np6w7ghog4kKw/yWjg13WNyszMmkaeM5L3R8QfASKiBzhpU27HNTOzoSnXVLuSPibpNABJOwEv1zcsMzNrFnkSyUXAPvzllt/ngW/VLSIzM2sqeS5tvSsi3iGpCyAinpXkKXfNzAzId0ayVtIIsvGvkNQOvFLXqMzMrGnkSSQXkA1T8gZJXwH+F/hqXaMyM7OmkWeGxB9JWgi8DxAwJSLuq3tkZmbWFHLNkJiGjr+/zrGYmVkTynNpy8zMrE9OJGZmVhUnEjMzq0qe+UgOl/SApOckrZH0vKQ1AxGcmZkNfnka288BDvGdWmZmVkqeRPKkk4jZ8OC5P2xT5EkknZKuAuYCfyoURsScukVlZgNublc3M+YsoWftegC6V/cwY84SACcTKytPY/vrgZfI5k4/JD0OrmdQZjbwZs5f9moSKehZu56Z85c1KCJrFnl6tn9yUw4s6XKyhLMyIvYosX0ScB3wSCqaExFnSnoj8H1ge7IxvS6NiG+kfc4APg2sSvv8e0TM25T4zGxDK1b39KvcrKBiIpF0QYni54DOiLiuzK6zgAvJkkJfbo+I3mc364DPR8RdkrYEFkq6MSLuTdvPi4hzK8VtZv0zuq2V7hJJY3RbawOisWaS59LWSGAC8EB6vA3YBjhO0vl97RQRC4Bn+htQRDwREXel5eeB+wBfoDWrs+mTx9PaMmKDstaWEUyfPL5BEVmzyNPY/iZg/4hYByDpYuCXwAHAkiqffx9JdwMrgC9ExD3FGyWNBSYCdxYVf07SJ4BOsjOXZ0sdWNI0YBrATjvtVGWYZkNfoUHdd21ZfykiyleQlgF7R8RzaX0r4M6IeIukroiYWGbfscDP+mgjeT3wSkS8IOkg4BsRMa5o+18BtwFfKdwhJmk74CmyuVG+BOwQEf9Y6UV2dHREZ2dnpWpmZlZE0sKI6KhUL8+lrXOARZK+J2kW0AWcK+l1wE2bGmBErImIF9LyPKBF0qgUfAvwE+BHxbcZR8STEbE+Il4BvgPsvanPb2ZmtZHnrq3LJM0j+9IW2Z1SK9Lm6Zv6xJK2J+vsGJL2JktqT0sScBlwX0R8vdc+O0TEE2n1MGDppj6/mZnVRp+JRNJbIuJ+Se9IRY+nv9tL2r7QIF5m/9nAJGCUpOXA6UALQERcAkwFPitpHdADHJWSynuAjwNLJC1Khyvc5nuOpAlkl7YeBT7T71dsZmY11WcbiaRLI2KapFtKbI6I2L++odWO20jMzPovbxtJn2ckETEt/d2vloGZmdnQkmuqXUnvBsYW14+Ich0NzcxsmMjTs/0HwK7AIqAwEE9Qvse6mZkNE3nOSDqA3aJShxMzMxuW8vQjWUo2gKKZmdlG8pyRjALulfQ7NpyP5NC6RWVmZk0jTyI5o95BmJlZ88rTs/02STsD4yLiJkmvBUZU2s/MzIaHim0kkj4NXAN8OxWNIZt218zMLNelrRPIxtm6EyAiHpD0hrpGZTbEze3q9nDtNmTkSSR/iog/Z2MpgqTNyPqRmNkmmNvVzYw5S16dH717dQ8z5mRT+ziZWDPKc/vvbZL+HWiVdABwNfDT+oZlNnTNnL/s1SRS0LN2PTPnL2tQRGbVyZNITgFWkc2G+BlgHnBqPYMyG8pWlJgXvVy52WCX566tVyRdQdZGEsAy93I323Sj21rpLpE0Rre1NiAas+rluWvr74GHgAuAC4EHJX2w3oGZDVXTJ4+ntWXDO+hbW0YwffL4BkVkVp08je3/DewXEQ8CSNoV+DlwQz0DMxuqCg3qvmvLhoo8iWRlIYkkDwMr6xSP2bAwZeIYJw4bMvq8tCXpcEmHA/dImifpWEnHkN2x9fs8B5d0uaSVkkrOrS5pkqTnJC1Kj9OKth0oaZmkByWdUlS+i6Q7JT0g6SpJm+d+tWZmVnPl2kgOSY+RwJPA35HNwb4K2Drn8WcBB1aoc3tETEiPMwEkjQC+BXwQ2A04WtJuqf7ZwHkRMQ54FjguZyxmZlYH5aba/WS1B4+IBZLGbsKuewMPRsTDAJKuBD4k6T5gf+Cjqd4VZINKXlxtrGZmtmny9COpt30k3S3pBkm7p7IxwONFdZansm2B1RGxrle5mZk1SK452+voLmDniHhB0kFkg0GOA1SibpQp34ikacA0gJ122qk20ZqZ2UYaekYSEWsi4oW0PA9okTSK7EzjjUVVdwRWAE8BbWm8r+LyUse+NCI6IqKjvb29bq/BzGy4q3hGImkL4MPA2OL6hYbxakjaHngyIkLS3mSJ7WlgNTBO0i5AN3AU8NFU7xZgKnAlcAxwXbVxmJnZpstzaes64DlgIUVT7eYhaTbZnV6jJC0HTgdaACLiErKE8FlJ64Ae4Kg0/Mo6SZ8D5pNNonV5RNyTDnsycKWkLwNdwGX9icnMzGpLlYbNkrQ0IvYYoHjqoqOjIzo7OxsdhplZU5G0MCI6KtXL00byG0l71iAmMzMbgvJc2noPcKykR8gubQmIiHhbXSMzM7OmkCeReKRfMzPrU8VLWxHxGNDGX4ZMaUtlZmZmuW7//Wfg08CcVPRDSZdGxDfrGplZjczt6vaQ7WZ1lOfS1nHAuyLiRQBJZwO/BZxIbNCb29XNjDlLXp0jvXt1DzPmLAFwMjGrkTx3bQlYX7S+ntJDlZgNOjPnL3s1iRT0rF3PzPnLGhSR2dCT54zke8Cdkq5N61NwJ0BrEitKzI1ertzM+q9iIomIr0u6lew2YAGfjIiuegdmVguj21rpLpE0Rre1NiAas6Ep16CNEXFXRFwQEd9wErFmMn3yeFpbRmxQ1toygumTxzcoIrOhp9HDyJvVVaFB3XdtmdWPE4kNeVMmjnHiMKujipe2JH1OUt452s3MbJjJ00ayPfB7ST+WdKAk3/prZmavyjNEyqlk099eBhwLPCDpq5J2rXNsZmbWBPLetRXA/6XHOmBr4BpJ59QxNjMzawJ5xto6iWxK26eA7wLTI2KtpNcADwBfrG+IZmY2mOU5IxkFHB4RkyPi6ohYCxARrwAH97WTpMslrZS0tNzBJe0lab2kqWl9P0mLih4vS5qSts2S9EjRtgm5X6mZmdVFnkQyD3imsCJpS0nvAoiI+8rsNws4sNyBJY0Aziabm510zFsiYkJETAD2B14Cflm02/TC9ohYlCN+MzOrozyJ5GLghaL1F1NZWRGxgKIE1IcTgZ8AK/vYPhW4ISJeyhGnmZk1QK7Rf1NjO/DqJa2qOzJKGgMcBlxSptpRwOxeZV+RtFjSeZK2qDYOMzOrTp5E8rCkkyS1pMc/Aw/X4LnPB06OiPWlNkraAdiTostewAzgLcBewDbAyX0dXNI0SZ2SOletWlWDcM3MrJQ8ieR44N1AN7AceBcwrQbP3QFcKelRsktYFxUa1ZMjgGsLjfsAEfFEZP5ENrz93n0dPCIujYiOiOhob2+vQbhmZlZKnmHkV5JdYqqpiNilsCxpFvCziJhbVOVosjMQiurtEBFPpN71U4Cyd4SZmVn95elHMpJsut3dgZGF8oj4xwr7zQYmAaMkLQdOB1rSvuXaRZA0FngjcFuvTT+S1E42L8oisrMlG0Q8P7rZ8JOn0fwHwP3AZOBM4B+Acrf9AhARR+cNIiKO7bX+KLDRt09E7J/3mDbwPD+62fCUp43kTRHxn8CLEXEF8PdkjeBmG/D86GbDU55EUmjsXi1pD2ArYGzdIrKm5fnRzYanPInk0jQfyanA9cC9ZL3RzTbQ1zzonh/dbGgrm0jSwIxrIuLZiFgQEX8dEW+IiG8PUHzWRDw/utnwVDaRpF7snxugWKzJTZk4hq8dvidj2loRMKatla8dvqcb2s2GuDx3bd0o6QvAVWTjbAEQEZXG0bJhyPOjmw0/eRJJob/ICUVlAfx17cMxM7Nmk6dn+y6V6piZ2fCVp2f7J0qVR8T3ax+OmZk1mzyXtvYqWh4JvA+4C3AiMTOzXJe2Tixel7QV2bApZmZmuTok9vYSMK7WgZiZWXPK00byU7K7tCBLPLsBP65nUGZm1jzytJGcW7S8DngsIpbXKR4zM2syeRLJH4EnIuJlAEmtksamod7NzGyYy9NGcjXwStH6+lRmZmaWK5FsFhF/Lqyk5c3rF5KZmTWTPIlklaRDCyuSPgQ8lefgki6XtFJS2bnVJe0lab2kqUVl6yUtSo/ri8p3kXSnpAckXSXJSc3MrIHytJEcTzZX+oVpfTlQsrd7CbOACynTeVHSCLL5Teb32tQTERNK7HI2cF5EXCnpErL55C/OGc+Q4vnRzWwwqHhGEhEPRcTfkN32u3tEvDsiHsxz8IhYAFQaJfhE4CfAykrHkyRgf+CaVHQFMCVPLENNYX707tU9BH+ZH31uV3ejQzOzYaZiIpH0VUltEfFCRDwvaWtJX67Fk0saAxwGXFJi80hJnZLukFRIFtsCqyNiXVpfDgzLn+CeH93MBos8bSQfjIjVhZWIeBY4qEbPfz5wckSsL7Ftp4joAD4KnC9pV0Al6kWJMiRNS4moc9WqVTUKd/Dw/OhmNljkSSQjJG1RWJHUCmxRpn5/dABXSnoUmApcVDj7iIgV6e/DwK3ARLJG/jZJhbadHYEVpQ4cEZdGREdEdLS3t9co3MHD86Ob2WCRJ5H8EPiVpOMk/SNwIzUa+TcidomIsRExlqzd458iYm66fLYFgKRRwL7AvRERwC1kSQfgGOC6WsTSbDw/upkNFnlG/z1H0mLg/WSXlr4UEb3vsCpJ0mxgEjBK0nLgdKAlHbdUu0jBW4FvS3qFLNmdFRH3pm0nk53FfBnoAi7LE8tQU7g7y3dtmVmjKfuR348dpH2Bj0bECRUrDxIdHR3R2dnZ6DDMzJqKpIWprbqsPP1IkDQBOBo4EngEmFNdeGZmNlT0mUgkvRk4iiyBPA1cRXYGs98AxWZmZk2g3BnJ/cDtwCGFDoiS/nVAojIzs6ZR7q6tDwP/B9wi6TuS3kfpfhxmZjaM9ZlIIuLaiDgSeAtZP45/BbaTdLGkDwxQfGZmNsjlGWvrxYj4UUQcTNYBcBFwSt0jMzOzppCnQ+KrIuKZiPh2ROxfr4DMzKy59CuRmJmZ9eZEYmZmVXEiMTOzquTq2W6ejdDMrC9OJDkUZiMsTCRVmI0QcDIxs2HPl7Zy8GyEZmZ9cyLJwbMRmpn1zYkkB89GaGbWNyeSHDwboZlZ39zYnoNnIzQz65sTSU5TJo5x4jAzK6Ful7YkXS5ppaSlFertJWm9pKlpfYKk30q6R9JiSUcW1Z0l6RFJi9JjQr3iNzOzfOrZRjILOLBcBUkjgLOB+UXFLwGfiIjd0/7nS2or2j49Iiakx6Iax2xmZv1Ut0QSEQuAZypUOxH4CbCyaL8/RMQDaXlF2tZerzjNzKw6DbtrS9IY4DDgkjJ19gY2Bx4qKv5KuuR1nqQtyuw7TVKnpM5Vq1bVLG4zM9tQI2//PR84OSLWl9ooaQfgB8AnI+KVVDyDbMbGvYBtgJP7OnhEXBoRHRHR0d7uExozs3pp5F1bHcCVkgBGAQdJWhcRcyW9Hvg5cGpE3FHYISKeSIt/kvQ94AsDHbSZmW2oYYkkInYpLEuaBfwsJZHNgWuB70fE1cX7SNohIp5Qln2mAGXvCDMzs/qrWyKRNBuYBIyStBw4HWgBiIg+20WAI4D3AttKOjaVHZvu0PqRpHZAZHPHH1+f6M3MLC9FRKNjqLuOjo7o7OxsdBhmZk1F0sKI6KhUz2NtmZlZVZxIzMysKk4kZmZWFScSMzOrihOJmZlVxYnEzMyq4kRiZmZVcSIxM7OqOJGYmVlVnEjMzKwqTiRmZlaVYTHWlqRVwGM1Otwo4KkaHatWHFM+jim/wRiXY8qnljHtHBEVJ3QaFomkliR15hnEbCA5pnwcU36DMS7HlE8jYvKlLTMzq4oTiZmZVcWJpP8ubXQAJTimfBxTfoMxLseUz4DH5DYSMzOris9IzMysKk4kJUg6UNIySQ9KOqXE9vdKukvSOklTB0lM/ybpXkmLJf1K0s6DJK7jJS2RtEjS/0rardExFdWbKikk1f0Olxzv07GSVqX3aZGkTzU6plTniPTv6h5J/9PomCSdV/Qe/UHS6nrHlDOunSTdIqkr/R88aBDEtHP6Llgs6VZJO9YtmIjwo+gBjAAeAv4a2By4G9itV52xwNuA7wNTB0lM+wGvTcufBa4aJHG9vmj5UOAXjY4p1dsSWADcAXQ0OibgWODCen9m/YxpHNAFbJ3W39DomHrVPxG4fJC8V5cCn03LuwGPDoKYrgaOScv7Az+oVzw+I9nY3sCDEfFwRPwZuBL4UHGFiHg0IhYDrwyimG6JiJfS6h1A/X599C+uNUWrrwPq3ShXMabkS8A5wMt1jqc/MQ2kPDF9GvhWRDwLEBErB0FMxY4GZtc5prxxBfD6tLwVsGIQxLQb8Ku0fEuJ7TXjRLKxMcDjRevLU1kj9Tem44Ab6hpRJldckk6Q9BDZF/dJjY5J0kTgjRHxszrHkjum5MPpMsQ1kt44CGJ6M/BmSb+WdIekAwdBTEB22QbYBbi5zjHljesM4GOSlgPzyM6WGh3T3cCH0/JhwJaStq1HME4kG1OJskbf2pY7JkkfAzqAmXWNKD1dibKN4oqIb0XErsDJwKmNjEnSa4DzgM/XOY5ied6nnwJjI+JtwE3AFYMgps3ILm9NIvv1/11JbQ2OqeAo4JqIWF/HeAryxHU0MCsidgQOAn6Q/q01MqYvAH8nqQv4O6AbWFePYJxINrYcKP41uCP1P02tJFdMkt4P/AdwaET8abDEVeRKYEpdI6oc05bAHsCtkh4F/ga4vs4N7hXfp4h4uugz+w7wzjrGkyumVOe6iFgbEY8Ay8gSSyNjKjiKgbmsBfniOg74MUBE/BYYSTbmVcNiiogVEXF4REwk+14gIp6rSzT1bqhqtgfZr7CHyU6bC41Yu/dRdxYD09heMSZgIlnj27jB9F4VxwMcAnQ2OqZe9W+l/o3ted6nHYqWDwPuGAQxHQhckZZHkV1K2bbRnx0wHniU1A+u3o+c79UNwLFp+a1kX+p1iy9nTKOA16TlrwBn1i2egfggmu1Bdmr6h/TF/B+p7EyyX/oAe5H9IngReBq4ZxDEdBPwJLAoPa4fJO/VN4B7Uky3lPtSH6iYetWteyLJ+T59Lb1Pd6f36S2DICYBXwfuBZYARzU6prR+BnBWvWPp53u1G/Dr9PktAj4wCGKaCjyQ6nwX2KJesbhnu5mZVcVtJGZmVhUnEjMzq4oTiZmZVcWJxMzMquJEYmZmVXEiGcYkrS8aSXWRpLE1OOaU4hF+JZ2ZOkrWjaTZaWiRfy0XSz+Od2i5UYOrlUb6HZ1nm6RHJeXu2CZpwkCMPDvYbOrrTqPiDqo515vRZo0OwBqqJyIm9LVR0mYR0d8hFaYAPyPre0BEnFZFfBVJ2h54d0SUGjZ/g1h67dfna4uI64Hraxroho4FllK613a5bXlMIBsiZ94m7j+gJI2IomFOJImsI19/B0Rtqtc95Axkpx4/Btd+ghbYAAAFrUlEQVQDeKFE2bFkw0//lGxAvL8iG0H0LrJOaR8qqvsJYDFZJ6wfAO8GngEeIeuUtStFvf+B95ENS74EuJzUQYqsl/J/FT3HRp3xyIac+F7a3gXsl8oXAz3p+f62qH6pWG4FvgrcRjbW1iHAnel4NwHbFb0HF6blWcAFwG/IehJvNJIB2ajGP0/vw1LgyFT+zvRcC4H5wA5kncReIBtuZBHQWnScjbb19d6Qjf76mxT7b8h6e28O/BFYlfY/slec84C3peUu4LS0/CXgU3191n29vl7HflN6D+9O++9K1qFxZtpnSdH7Moms0+X/kCX5scB9wEUprp0p+reZ3pdZRZ/HJcDtZB3tDi71ulPMlwO/T8csvJZWsqF6FgNXpc+/7h1Sh/qj4QH40cAPH9bzl57w16ayY8l67W+T1jcjzSlCNuTCg+kLYvf0hTcqbSvUn0XRl21hnSwRPA68OZV/H/iXtPwocGJa/ifguyVi/TzwvbT8lvTFMTJ9CS3t4/X1juVW4KKi9a35y3TTnwL+u+g9KE4kV5NdBt6NbOju3s/zYeA7RetbAS1kX/DtqexI0twZlOlN33tbX+8N2ZDlm6Xl9wM/6R17iWOfApyQ9v09MD+V30KWiPr6rDd6fSWOfSdwWFoeCbw27Xcj2dwZ26XPbAeyRPIisEuqP5ZsSoa/KTpeuUTyi/R5jCP7tzqy9+sm+8HwsbTcRpZ0Xgf8W9Hn8DayQQydSKp8+NLW8NbXpa0bI+KZtCzgq5LeS/affQzZl8L+ZKOvPgVQVL8v44FHIuIPaf0Ksi+189P6nPR3IXB4if3fA3wzPdf9kh4jG+Z8TYm65VxVtLwjcJWkHch+1T7Sxz5zI7vUcq+k7UpsXwKcK+ls4GcRcbukPcgGh7wxu1rDCOCJfsZaUOq92Qq4QtI4slFfW3Ic53ayYfwfITvDOEDSa8lGHV4mqYXSn/VGr6/4oJK2BMZExLUAEfFyKn8PMDuyS1dPSrqNbHihNcDvIhsIsuCxiLgj5/vx4/R5PCDpYbIfFr19ADhU0hfS+khgJ+C9ZGeYRMRiSYtzPqeV4URipbxYtPwPQDvwzohYm0bMHUmWYPozvk6pYa+LFUa+XU/pf5eV9s+r+LV9E/h6RFwvaRLZGE7lYisZR0T8QdI7ycY++pqkXwLXko3Btk8NYi713nwJuCUiDks3Sdya4zi/J2tHeJjsTGEU2eRVC9P2kp91qdcXEWcWHbevz6bcZ/ZihfXif1sjy2wrtV547g9HxLINCrOk7nGhasx3bVklWwEr0xfLfmTXryG7ln5EYaIcSduk8ufJhmrv7X5grKQ3pfWPk7Uf5LWA7IsOSW8m+3W5rOwefcdSsBXZHA0Ax/Qjlg2ku6xeiogfAucC70ixtUvaJ9VpkbR7jrgqxVwq9mPz7B/ZTHqPA0eQzaJ5O9mcFYUzjJKfdR+vr/i4a4Dlkqak+lukM50FwJGSRkhqJzsb+F2O1wbZGcxb05weh/Xa9hFJr5G0K9lUs8tKvO75wImp8b4wmRls+O9oD7LLW1YlJxKr5EdAh6ROsv+A9wNExD1kQ1PfJuluslFiIWvInC6pK/1HJ9V/GfgkcLWkJWSXTi7pRxwXASPSvleRDdldac6VkrEUOSPFczvwVD9i6W1P4HeSFpHN+/Dl9KU9FTg7vT+LyG4AgNRgnG65bu11rHLbip1Ddnbwa7LLZgW3ALul/Y8ssd/twJORTct8O9nlvUIiKflZl3p9JY77ceCkdKnoN8D2ZGdlhZsxbga+GBH/V+Y1FTuF7I67m9n4kuAysh8hNwDHp39bvV/3l8gu9y2WtDStA1wM/FWK84vkT2xWhkf/NbOmIWkWWTvNNY2Oxf7CZyRmZlYVn5GYmVlVfEZiZmZVcSIxM7OqOJGYmVlVnEjMzKwqTiRmZlYVJxIzM6vK/wO1smtZB7co8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.scatter(frac_array, loss_benign_poison_lst)\n",
    "plt.ylabel('Loss on benign examples')\n",
    "plt.xlabel('Fraction of train set that was corrupted')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "#plt.savefig('Random_blackout_whiteout_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_array = []\n",
    "for i in range(1, len(frac_array)):\n",
    "    diff_array.append(acc_corrupt_poison_lst[i] - acc_corrupt_poison_lst[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0009000000000000119,\n",
       " -0.00660000000000005,\n",
       " -0.012399999999999967,\n",
       " -0.01429999999999998,\n",
       " -0.0049000000000000155,\n",
       " -0.010000000000000009,\n",
       " -0.0004999999999999449,\n",
       " -0.016300000000000092]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens to the test accuracy on corrupted points when % corrupted in train set increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_corruption import gaussian_blurring, corrupt_data, random_perturbation, random_blackout_whiteout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function that inputs frac_corrupted as a parameter and outputs test accuracy on fully corrupted points.\n",
    "def train_and_report(x_train, y_train, x_test, y_test, reg = 1e-3, corrupt_func = None, frac = 0.4):\n",
    "    \n",
    "    #Config\n",
    "    num_classes = 10\n",
    "    \n",
    "    x_train_flat, input_shape = flatten_mnist(x_train)\n",
    "    x_test_flat, _ = flatten_mnist(x_test)\n",
    "    \n",
    "    print(\"Frac value:\" + str(frac))\n",
    "   \n",
    "    #Fit corrupted data\n",
    "    model = create_fully_connected(input_shape = input_shape, num_classes = num_classes, reg = reg)\n",
    "    model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    x_train_corrupt = corrupt_data(x_train, int(np.round(frac*x_train.shape[0])), corrupt_func)\n",
    "    x_train_corrupt_flat, _ = flatten_mnist(x_train_corrupt)\n",
    "    \n",
    "    \n",
    "    model.fit(x_train_flat, y_train, batch_size=128, epochs=15, verbose=True, validation_split=.1)\n",
    "    \n",
    "    _, _, loss_corrupt_poison, acc_corrupt_poison = evaluate_on_both(model, x_test_flat, y_test, corrupt_func)\n",
    "    \n",
    "    return loss_corrupt_poison, acc_corrupt_poison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac value:0.1\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 2.4370 - acc: 0.0841 - val_loss: 2.3918 - val_acc: 0.1065\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.3791 - acc: 0.1721 - val_loss: 2.3657 - val_acc: 0.2062\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.3531 - acc: 0.2457 - val_loss: 2.3380 - val_acc: 0.3015\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 2.3237 - acc: 0.3454 - val_loss: 2.3048 - val_acc: 0.3697\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.2877 - acc: 0.3966 - val_loss: 2.2635 - val_acc: 0.4925\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.2422 - acc: 0.4695 - val_loss: 2.2114 - val_acc: 0.5113\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.1846 - acc: 0.4934 - val_loss: 2.1455 - val_acc: 0.5547\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.1141 - acc: 0.5246 - val_loss: 2.0668 - val_acc: 0.5503\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.0320 - acc: 0.5435 - val_loss: 1.9769 - val_acc: 0.5873\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 1.9419 - acc: 0.5689 - val_loss: 1.8805 - val_acc: 0.6177\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.8483 - acc: 0.6015 - val_loss: 1.7823 - val_acc: 0.6415\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.7554 - acc: 0.6252 - val_loss: 1.6862 - val_acc: 0.6852\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.6663 - acc: 0.6535 - val_loss: 1.5953 - val_acc: 0.7140\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.5832 - acc: 0.6811 - val_loss: 1.5109 - val_acc: 0.7240\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.5074 - acc: 0.6931 - val_loss: 1.4351 - val_acc: 0.7462\n",
      "Frac value:0.30000000000000004\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Frac value:0.5000000000000001\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s 28us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 20us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 18us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 19us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 12us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 12us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 12us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 12us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Frac value:0.7000000000000001\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s 24us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 17us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 16us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n",
      "Frac value:0.9000000000000001\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 1s 23us/step - loss: 2.4256 - acc: 0.1459 - val_loss: 2.3832 - val_acc: 0.2612\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 2.3710 - acc: 0.2123 - val_loss: 2.3559 - val_acc: 0.2808\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.3427 - acc: 0.2978 - val_loss: 2.3243 - val_acc: 0.4162\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 2.3090 - acc: 0.3987 - val_loss: 2.2859 - val_acc: 0.4723\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 2.2666 - acc: 0.4660 - val_loss: 2.2370 - val_acc: 0.5148\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.2131 - acc: 0.5066 - val_loss: 2.1756 - val_acc: 0.5563\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 2.1466 - acc: 0.5364 - val_loss: 2.1005 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 2.0677 - acc: 0.5615 - val_loss: 2.0137 - val_acc: 0.5953\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 1.9796 - acc: 0.5799 - val_loss: 1.9192 - val_acc: 0.6217\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 1.8863 - acc: 0.5906 - val_loss: 1.8206 - val_acc: 0.6297\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 1s 13us/step - loss: 1.7919 - acc: 0.6162 - val_loss: 1.7229 - val_acc: 0.6347\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.7006 - acc: 0.6291 - val_loss: 1.6303 - val_acc: 0.6800\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 1.6152 - acc: 0.6536 - val_loss: 1.5443 - val_acc: 0.6903\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 1s 15us/step - loss: 1.5371 - acc: 0.6694 - val_loss: 1.4661 - val_acc: 0.7205\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 1s 14us/step - loss: 1.4661 - acc: 0.6915 - val_loss: 1.3949 - val_acc: 0.7257\n"
     ]
    }
   ],
   "source": [
    "frac_array = np.arange(0.1, 1.0, 0.2)\n",
    "loss_corrupt_poison_lst, acc_corrupt_poison_lst = [], []\n",
    "for frac in frac_array:\n",
    "    loss_corrupt_poison, acc_corrupt_poison = train_and_report(x_train, y_train, x_test, y_test, corrupt_func = random_perturbation, frac = frac)\n",
    "    loss_corrupt_poison_lst.append(loss_corrupt_poison)\n",
    "    acc_corrupt_poison_lst.append(acc_corrupt_poison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frac_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7cd0ca87d4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_corrupt_poison_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fraction of training set corrupted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy on benign of model trained on corrupted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frac_array' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(frac_array, acc_corrupt_poison_lst)\n",
    "plt.xlabel('Fraction of training set corrupted')\n",
    "plt.ylabel('Accuracy on benign of model trained on corrupted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does correlation change with frac of training corrupted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac value:0.1\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-4aa61d01c1a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreg_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrupt_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_blurring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss_stab_proxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0macc_stab_proxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-c750c4a21c15>\u001b[0m in \u001b[0;36mcompile_train_test\u001b[0;34m(x_train, y_train, x_test, y_test, reg, corrupt_func, frac)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_fully_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sgd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mloss_benign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_benign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_corrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_corrupt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_on_both\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrupt_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frac_array = np.arange(0.1, 1.0, 0.2)\n",
    "reg_array = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "loss_pearson = []\n",
    "acc_pearson = []\n",
    "sg_dict = {}\n",
    "\n",
    "\n",
    "for frac in frac_array:\n",
    "    loss_stab_proxy, loss_gen_proxy, acc_stab_proxy, acc_gen_proxy = [], [], [], []\n",
    "    \n",
    "    for reg in reg_array:\n",
    "        x_loss, x_acc, y_loss, y_acc = compile_train_test(x_train, y_train, x_test, y_test, corrupt_func = gaussian_blurring, reg = reg, frac = frac)\n",
    "        loss_stab_proxy.append(x_loss)\n",
    "        acc_stab_proxy.append(x_acc)\n",
    "        loss_gen_proxy.append(y_loss)\n",
    "        acc_gen_proxy.append(y_acc)\n",
    "    \n",
    "    sg_dict[frac] = (loss_stab_proxy, loss_gen_proxy)\n",
    "    \n",
    "    loss_corr, _ = sp.stats.pearsonr(loss_stab_proxy, loss_gen_proxy)\n",
    "    acc_corr, _ = sp.stats.pearsonr(acc_stab_proxy, acc_gen_proxy)\n",
    "    \n",
    "    loss_pearson.append(loss_corr)\n",
    "    acc_pearson.append(acc_corr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9978624801068675, 0.9980280247906131, 0.9980988564012216, 0.9981658578130178, 0.9981684373467914]\n"
     ]
    }
   ],
   "source": [
    "print(loss_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYHFW5x/HvjyQssgVIWLOBIhg0soyA1wUUFYIKCLhw2UVRr+tFEFGvQARBcbu4ISKbIqAoi1yUTcImASeEBAKCAYEsKIEQCJsk4b1/nNNQDD3dNemp6Wny+zxPPVN96lTVW9U9/XbVqTqliMDMzGxZrdDuAMzMrLM5kZiZWUucSMzMrCVOJGZm1hInEjMza4kTiZmZtcSJxPpE0kxJO7Y7DitP0v2S3jVA61pF0h8kPS7ptwOxzsK6/dlsk6HtDsAGnqQANo2IWYWyY4DXRMR+jeaNiC0qDq/jld2Xr1B7A+sB60TEkqpWIulMYE5EfK1W5s9m+/iIxDqKpI7/8aPklfq/Nxa4p8okYoPPK/XDbC2QNELSpZIWSlog6fraF1/xNImkYyT9RtLZkhblUwtdheVsLWlanvZbSedLOq7Bej8u6a5c/05JWxfWeaSkGcBTkoZKep2kyTnGmZJ2Kyxn1zz/IklzJR3ebLvqxLKCpC9LulfSo3k7187TxkkKSQdKelDSI5K+mqftAnwF+LCkJyVNz+WTJR0v6UbgaWATSRtKuiTHMkvSxwvrP0bSBXmfLZJ0q6Q35mlHSPpdj3h/KOkHJd7blST9QNK8PPxA0kol3vcj875cJOluSTvVWfaxwNcL235I3o5fFerU9t3Qwn75hqQb87KvkDSiUP+tkv6SY5ot6SBJhwL7Al/K6/lD4XNS+2w22s4dJc2R9EVJD0t6SNLBzfadNRARHpazAQjSqZdi2THAr/L4CcApwLA8vA1QnnY/8K7CPM8CuwJD8nxT8rQVgQeAz+dl7Ak8BxzXS0wfBOYCbwIEvAYYW1jnbcBoYJW8vFmkL+wVgXcCi4DNcv2HgLfl8bWArZttV514vgBMAUYBKwE/A87N08blffjzHM8bgX8Dr+u5LwvLmww8CGxBOqU8DLgW+AmwMrAlMB/YqbCMxaRTRcOAw4F/5PENgKeA4bnuUOBhYJtetqX4nk3K27UuMBL4C/CNRvsH2AyYDWxY2P5X97Kul2x7nde1fTe0sF/uBV6b9+Vk4MQ8bUx+X/fJ8awDbJmnnUmPz1IftnNHYEmuM4z0+X0aWKvd/5udOviIxOpZTPqyGhsRiyPi+sj/gXXcEBGXRcRS4JekL1WA7UlfcCfnZfweuKXBOj8GfDsi/hrJrIh4oDD95IiYHRHP5GWvRvrCeS4i/gxcSvrCqcU/XtIaEfFYRNy6DNv1CeCrETEnIv5N+kLcWy89tXZsRDwTEdOB6YVt782ZETEz0mmf9YG3AkdGxLMRcRtwGrB/of7UiLggIhYD3yMlnO0j4iHgOlLyBdgFeCQipjZZP6Rf8pMi4uGImA8cW1hnb/tnKSmZjpc0LCLuj4h7S6yrrDMi4p783v6GlFRrsV4VEefmeB7N+6mMRtsJaVsn5eVeBjxJSpi2DJxIlk9LSb/EioaR/rkATiL94r9C0n2SvtxgWf8sjD8NrJy/bDcE5vb4op7dYDmjSb9Me1Ocd0NgdkQ8Xyh7ANgoj+9F+pX5gKRrJb05l9fdLkn75lMkT0r6Y647Frgwn1JZCNxF2m/rNdj21RrEX28bFkTEol624SX187bOyfMBnAXUGvP3IyXxMjbM6ymus7bMuvsn0kUZXyAl04clnSdpQ/pPb/ux2WeikUbbCfBovLQdp8z7Z71wIlk+PUg6xVC0MfkfLyIWRcQXI2IT4P3AYfXOiTfxELCRJBXKRjeoPxt4dYPpxYQ0Dxjdo31jDOnUGPmoZnfSaY2LSL9ye92uiDgnIlbLw8RCPBMjYnhhWDki5jbfdHo7yum5DWtLWr3eNmQv7K+8raPyfOTtmiDp9cD7gHNKxFVb79ge65wHjd/3iPh1RLw1zxvAt0qu7yngVYXX65ecDxp/Jpp1W97rdlr/cyJZPp0PfE3SqNyo/C7SF8cFAJLeJ+k1OQk8QfolvrSP67gpz/MZpcbx3YFtG9Q/DThc0jZKXiNpbC91byZ9QX1J0jClewfeD5wnacV8hLFmPiVUi7+v23UKcHwtBkkj8zaU8S9gnBpcmRURs0nn7U+QtLKkCcAhvDQhbCNpz3yE9wVSO8yUPP+zpPfr18AtEfFgydjOJb33I3Oj9teBX+VtrLt/JG0m6Z25sfpZ4BnKfx5uA94uaYykNYGjSs4HaV+8S9KH8mdoHUm1017/AjZZlu20/udEsnyaRPoSuwF4DPg2sG9E3JGnbwpcRTpvfBPwk4iY3JcVRMRzpAb2Q4CFpNMvl5K+DOvV/y1wPOmLcRHpF/faDZa9GzAReITUYH1ARPwtV9kfuF/SE8AnefEUUF+263+BS0ineRaRvsC3K7HpALUb8R6VdGuDevuQjgznARcCR0fElYXpFwMfJr1H+wN75uRYcxbwBsqf1gI4DugGZgC3A7fmMuh9/6wEnEja1/8kHel9pczK8vacn9c3lfQZKCUnx12BLwILSEmp1g71C1KbzUJJF/VxO62f1a7EMaucpJuBUyLijHbHMtipxE2NksYAfwPWj4gnBio2s558RGKVkbSDpPXzaYkDgQnAn9od1ytBPm12GHCek4i1W8ffJWyD2makhu7VSFff7J0vXbUWSFqV1EbwAOnSX7O28qktMzNriU9tmZlZS5aLU1sjRoyIcePGtTsMM7OOMnXq1EciYmSzestFIhk3bhzd3d3tDsPMrKNIeqB5LZ/aMjOzFjmRmJlZS5xIzMysJU4kZmbWEicSMzNriROJmZm1xInEzMxa4kRiZmYtcSIxM7OWOJGYmVlLnEjMzKwlTiRmZtYSJxIzM2uJE4mZmbXEicTMzFriRGJmZi1xIjEzs5Y4kZiZWUucSMzMrCWVJRJJp0t6WNIdvUyXpJMlzZI0Q9LWhWl/krRQ0qU95tlY0s2S/i7pfEkrVhW/mZmVU+URyZnALg2mTwQ2zcOhwE8L004C9q8zz7eA70fEpsBjwCH9EqmZmS2zyhJJRFwHLGhQZXfg7EimAMMlbZDnvRpYVKwsScA7gQty0VnAHv0euJmZ9Uk720g2AmYXXs/JZb1ZB1gYEUvK1Jd0qKRuSd3z589vOVgzM6uvnYlEdcqiv+pHxKkR0RURXSNHjuxzcGZmVk47E8kcYHTh9ShgXoP6j5BOfw0tWd/MzAZAOxPJJcAB+eqt7YHHI+Kh3ipHRADXAHvnogOBi6sP08zMGhnavMqykXQusCMwQtIc4GhgGEBEnAJcBuwKzAKeBg4uzHs9sDmwWp73kIi4HDgSOE/SccA04BdVxW9mZuVUlkgiYp8m0wP4dC/T3tZL+X3Atq1HZ2Zm/cV3tpuZWUucSMzMrCVOJGZm1hInEjMza4kTiZmZtcSJxMzMWuJEYmZmLXEiMTOzljiRmJlZS3q9s13SKGBcRNyQXx8GrJYn/zoiZg1AfGZmNsg1OiI5CRheeP0J4ClS1+3HVhmUmZl1jkZ9bW0WEcVnpj8dEd+FFzpVNDMza3hEsnKP1zsVxtepIBYzM+tAjRLJIkmvrb2IiAUAkjYHnqw6MDMz6wyNTm0dDVwq6Xjg1ly2DfAV4PNVB2ZmZp2h10QSEX+StCfwJeBzufgOYM+IuGMggjMzs8Gv4YOtcsI4oGe5pJUj4tnKojIzs45R+oZESbdI+m9JGwBXVxiTmZl1kL7c2b4rsCbwAHB+NeGYmVmn6TWRSDpD0thC0ZrAB4FvAxOqDszMzDpDozaSrSPiAQBJ2wC/Bj4aETdKumVAojMzs0GvUSIJSW8HxgDfBCZGxExJKwGrD0h0ZmY26DVKJJ8AjgeeAy4GviTpauDDwCUDEJuZmXWARveR3Ay8q/Za0m7AzsCFwC+qD83MzDpBw/tIevgjMBuYGxFRUTxmZtZhGl21dYqkLfL4msB04GxgmqR9Big+MzMb5BrdR/K2iJiZxw8G7omIN5D62/pSswVLOl3Sw5Lqdqei5GRJsyTNkLR1YdqBkv6ehwML5ZMl3S3ptjysW2orzcysMo0SyXOF8XcDFwFExD9LLvtMYJcG0ycCm+bhUOCnAJLWJnUYuR2wLXC0pLUK8+0bEVvm4eGSsZiZWUUaJZKFkt4naSvgLcCfACQNBVZptuCIuA5Y0KDK7sDZkUwBhufuV3YGroyIBRHxGHAljROSmZm1UbPLf08G1ge+UDgS2Qn4v35Y90akxvuaObmst/KaMyQtBX4HHOeGfzOz9mp0+e891DkSiIjLgcv7Yd2qt9oG5ZBOa82VtDopkexPugDg5QuXDiWdMmPMmDGtR2tmZnX1pdPG/jYHGF14PQqY16CciJib/y4iddmybW8Lj4hTI6IrIrpGjhzZz6GbmVlNOxPJJcAB+eqt7YHHI+Ih0tHOeyStlRvZ3wNcLmmopBEAkoYB7yM9aMvMzNqoLzck9omkc4EdgRGS5pCuxBoGEBGnAJeRuqafBTxNusSYiFgg6RvAX/OiJuWyVUkJZRgwBLgK+HlV8ZuZWTlq1lYt6V5gCnA9cF1E3DkQgfWnrq6u6O7ubncYZmYdRdLUiOhqVq/Mqa3xwM+AdYDvSLpP0oWtBmhmZq8MZRLJUmBx/vs88C/ANwKamRlQro3kCeB24HvAzyPi0WpDMjOzTlLmiGQf4Drgv4DzJB0raadqwzIzs07R9IgkIi4GLpa0Oal/rC+QOm1s2k2KmZm98jU9IpH0u3zl1v8CqwIHAGs1nsvMzJYXvR6RSNog3yB4InBrRCwduLDMzKxTNDq1dXq+s3wysKqkGyJiycCEZWZmnaJRp40TJa1Mujv9A6R7SB4kdSf/p4h4cGBCNDOzwaxhY3tEPEtOHACSNiY1uP9I0voR0WuniWZmtnwo1deWpPVJPe0G8PuI+ImkFSuNzMzMOkKZq7Y+BtwC7AnsDUyR9NGIeK7xnGZmtjwoc0RyBLBV7Y52SesAfwFOrzIwMzPrDGXubJ8DLCq8XsRLH4VrZmbLsUb3kRyWR+cCN0u6mNRGsjvpVJeZmVnDU1ur57/35qHm4urCMTOzTtPoPpJjBzIQMzPrTO18ZruZmb0COJGYmVlLnEjMzKwlTe8jkTQS+Dgwrlg/Ij5aXVhmZtYpytyQeDFwPXAV6bntZmZmLyiTSF4VEUdWHomZmXWkMm0kl0ratfJIzMysI5VJJJ8nJZNnJS3KwxNVB2ZmZp2h6amtiFi9WR0zM1t+lX0eyW7A2/PLyRFxaXUhmZlZJynzPJITSae37szD53NZU5JOl/SwpDt6mS5JJ0uaJWmGpK0L0w6U9Pc8HFgo30bS7XmekyWpTCxmZlaNMm0kuwLvjojTI+J0YJdcVsaZuX5vJgKb5uFQ4KcAktYGjga2Iz2Z8WhJa+V5fprr1uZrtHwzM6tY2TvbhxfG1yy78Ii4DljQoMruwNmRTAGGS9oA2Bm4MiIWRMRjwJXALnnaGhFxU0QEcDawR9l4zMys/5VpIzkBmCbpGkCktpKj+mn9G/HSh2TNyWWNyufUKX8ZSYeSjlwYM2ZMP4VrZmY9lblq61xJk4E3kRLJkRHxz35af732jViG8pcXRpwKnArQ1dVVt46ZmbWu11NbkjbPf7cGNiD9+p8NbFhsFG/RHGB04fUoYF6T8lF1ys3MrE0aHZEcRjo19N060wJ4Zz+s/xLgM5LOIzWsPx4RD0m6HPhmoYH9PcBREbEg3xC5PXAzcADww36Iw8zMllGjJyQemkcnRsSzxWmSVi6zcEnnAjsCIyTNIV2JNSwv/xTgMtIVYLOAp4GD87QFkr4B/DUvalJE1BrtP0W6GmwV4I95MDOzNlG6+KlBBenWiNi6Wdlg1tXVFd3d3e0Ow8yso0iaGhFdzer1ekQiaX3SFVGrSNqKFxu61wBe1S9RmplZx2vURrIzcBCpQft7hfJFwFcqjMnMzDpIozaSs4CzJO0VEb8bwJjMzKyDlLmP5HeS3gtsAaxcKJ9UZWBmZtYZyjyz/RRSm8g7gNOAvYFbKo7L7BXtomlzOenyu5m38Bk2HL4KR+y8GXtsVbeThuWe91U57dxPZbpI+Y+ImCBpRkQcK+m7wO+rDsw6k//pm7to2lyO+v3tPLN4KQBzFz7DUb+/HcD7qgfvq3LavZ/KdNr4TP77tKQNgcXAxtWFNPhcNG0ubznxz2z85f/jLSf+mYumzW13SINS7cM8d+EzBC9+mL2/Xuqky+9+4R++5pnFSznp8rvbFNHg5X1VTrv3U9lntg8HTgJuBe4HzqsyqMHEX47ltfvD3CnmLXymT+XLM++rctq9n5omkoj4RkQszFdujQU2j4j/qT60wcFfjuW1+8PcKTYcvkqfypdn3lfltHs/Neq0cc+eA/BeYKc8vlzwl2N57f4wd4ojdt6MVYYNeUnZKsOGcMTOm7UposHL+6qcdu+nRo3t728wLVhOGtw3HL4Kc+skDX85vtwRO2/2kgY/8D99PbXGT1+U0Jz3VTnt3k9N+9p6JWilr62eV0NA+nI8Yc83+MNch6/aMnvlaLmvrcKC1gO+CWwYERMljQfeHBG/6Ic4B712Z/pOs8dWG3nfmC1nytxHciZwBvDV/Poe4HxguUgk4C9HM7NGylz+OyIifgM8DxARS4CljWcxM7PlRZlE8pSkdcjPRs9PJ3y80qjMzKxjlDm1dRjpkbivlnQjMJLU35aZmVnjRCJpBVKPvzsAm5EebnV3RCwegNjMzKwDNEwkEfG8pO9GxJuBmQMUk5mZdZAybSRXSNpLkppXNTOz5U3ZNpJVgSWSniWd3oqIWKPSyMzMrCM0ayMRsEVEPDhA8ZiZWYdpeGorUv8pFw5QLGZm1oHKtJFMkfSmyiMxM7OOVKaN5B3AJyQ9ADzFi20kEyqNzMzMOkKZRDKx8ijMzKxjlXlC4gPAcNLzSd4PDM9lTUnaRdLdkmZJ+nKd6WMlXS1phqTJkkYVpn1L0h15+HCh/ExJ/5B0Wx62LBOLmZlVo2kikfR54Bxg3Tz8StJnS8w3BPgx6YhmPLBP7oK+6DvA2fk02STghDzve4GtgS2B7YAjJBUvNz4iIrbMw23NYjEzs+qUaWw/BNguIr4eEV8Htgc+XmK+bYFZEXFfRDwHnAfs3qPOeODqPH5NYfp44NqIWBIRTwHTgV1KrNPMzAZYmUQiXtpt/NJc1sxGwOzC6zm5rGg6sFce/wCweu5peDowUdKrJI0gNfiPLsx3fD4d9n1JK9UNWjpUUrek7vnz55cI18zMlkWZRHIGcLOkYyQdA0yh3EOt6iWbns/1PRzYQdI0UseQc4ElEXEFcBnwF+Bc4CZgSZ7nKGBz4E3A2sCR9VYeEadGRFdEdI0cObJEuGZmtizKNLZ/DzgYWAA8BhwcET8osew5vPQoYhQwr8ey50XEnhGxFfkJjBHxeP57fG4DeTcpKf09lz8Uyb9JSW7bErGYmVlFer38N9+EOCIi/hgRtwK35vLdJK0QEVObLPuvwKaSNiYdaXwE+M8e6xgBLIiI50lHGqfn8iGkq8MelTQBmABckadtEBEP5e5b9gDu6PNWm5lZv2l0RHIScFed8jvztIbyI3k/A1yel/ObiJgpaZKk3XK1HYG7Jd0DrAccn8uHAddLuhM4FdgvLw/gHEm3A7cDI4DjmsViZmbVUepOq84E6faIeEMv06ZHxBsrjawfdXV1RXd3d7vDMDPrKJKmRkRXs3qNjkhWaTBt1b6HZGZmr0SNEslVko7v+UArSccCf642LDMz6xSN+tr6InAaMEtS7e7xNwLdwMeqDszMzDpDr4kk31G+j6RNgC1y8cyIuG9AIjMzs47QtPffnDicPMzMrK4yd7abmZn1yonEzMxaUubBVrU7zdcr1o+IB6sKyszMOkfTRJKfPXI08C/g+VwcpG5LzMxsOVfmiOTzwGYR8WjVwZiZWecp00YyG3i86kDMzKwzlTkiuQ+YLOn/gH/XCnP38mZmtpwrk0gezMOKeTAzM3tBmRsSjwWQtHp6GU9WHpWZmXWMpm0kkl6fH4V7BzBT0lRJWzSbz8zMlg9lGttPBQ6LiLERMZbUmePPqw3LzMw6RZlEsmpEXFN7ERGT8fNIzMwsK3XVlqT/AX6ZX+8H/KO6kMzMrJOUOSL5KDAS+D1wIek56QdXGZSZmXWOMldtPQZ8Dl7oc2vViHii6sDMzKwzlLlq69eS1pC0KjATuFvSEdWHZmZmnaDMqa3x+QhkD+AyYAywf6VRmZlZxyiTSIZJGkZKJBdHxGJS779mZmalEskpwP2kS36vkzQWcBuJmZkBTRrbJa0A/CsiNiqUPQi8o+rAzMysMzQ8IomI54HP9CiLiFhSaVRmZtYxypzaulLS4ZJGS1q7NlQemZmZdYSyNyR+GrgOmJqH7jILl7SLpLslzZL05TrTx0q6WtIMSZMljSpM+5akO/Lw4UL5xpJulvR3SedLctf2ZmZt1DSRRMTGdYZNms2Xb178MTARGA/sI2l8j2rfAc6OiAnAJOCEPO97ga2BLYHtgCMkrZHn+Rbw/YjYFHgMOKTMhpqZWTXKHJHUupL/kKQDakOJ2bYFZkXEfRHxHHAesHuPOuOBq/P4NYXp44FrI2JJRDwFTAd2kSTgncAFud5ZpMuSzcysTcrc2X408MM8vAP4NrBbiWVvRHree82cXFY0Hdgrj38AWF3SOrl8oqRXSRqR1zsaWAdYWGjsr7fMWtyHSuqW1D1//vwS4ZqZ2bIoc0SyN7AT8M+IOBh4I7BSiflUp6znjYyHAzvkB2ftAMwFlkTEFaS76P8CnAvcBCwpucxUGHFqRHRFRNfIkSNLhGtmZsuiTCJ5Jl8GvCS3UzwMNG0jIR0tjC68HgXMK1aIiHkRsWdEbAV8NZc9nv8eHxFbRsS7SQnk78AjwHBJQ3tbppmZDawyiaRb0nDSUxGnArcCt5SY76/ApvkqqxWBjwCXFCtIGpFvegQ4Cjg9lw/Jp7iQNAGYAFwREUFqS9k7z3MgcHGJWMzMrCJlupH/rzx6iqQ/AWtExIwS8y2R9BngcmAIcHpEzJQ0CeiOiEuAHYETJAXp8uJP59mHAdentnWeAPYrtIscCZwn6ThgGvCLcptqZmZVUPqR36BC+jbfF9gkIiZJGgOsHxFljkoGha6urujuLnXri5mZZZKmRkRXs3plTm39BHgzsE9+vYh0f4iZmVmpZ7ZvFxFb5yuriIjHfDe5mZnVlDkiWZzvUg8ASSOB5yuNyszMOkaZRHIycCGwrqTjgRuAb1YalZmZdYwyV22dI2kq6aZEAXtExF2VR2ZmZh2h10QiaWXgk8BrgNuBn/k5JGZm1lOjU1tnAV2kJDKR1FOvmZnZSzQ6tTU+It4AIOkXlLub3czMljONjkgW10Z8SsvMzHrT6IjkjZKeyOMCVsmvRXp0+xq9z2pmZsuLXhNJRAwZyEDMzKwzlXpCopmZWW+cSMzMrCVOJGZm1hInEjMza4kTiZmZtcSJxMzMWuJEYmZmLXEiMTOzljiRmJlZS5xIzMysJU4kZmbWEicSMzNriROJmZm1xInEzMxa4kRiZmYtqTSRSNpF0t2SZkn6cp3pYyVdLWmGpMmSRhWmfVvSTEl3STpZknL55LzM2/KwbpXbYGZmjVWWSCQNAX4MTATGA/tIGt+j2neAsyNiAjAJOCHP+x/AW4AJwOuBNwE7FObbNyK2zMPDVW2DmZk1V+URybbArIi4LyKeA84Ddu9RZzxwdR6/pjA9gJWBFYGVgGHAvyqM1czMllGViWQjYHbh9ZxcVjQd2CuPfwBYXdI6EXETKbE8lIfLI+Kuwnxn5NNa/1M75dWTpEMldUvqnj9/fn9sj5mZ1VFlIqn3BR89Xh8O7CBpGunU1VxgiaTXAK8DRpGSzzslvT3Ps29EvAF4Wx72r7fyiDg1IroiomvkyJGtb42ZmdVVZSKZA4wuvB4FzCtWiIh5EbFnRGwFfDWXPU46OpkSEU9GxJPAH4Ht8/S5+e8i4NekU2hmZtYmVSaSvwKbStpY0orAR4BLihUkjZBUi+Eo4PQ8/iDpSGWopGGko5W78usRed5hwPuAOyrcBjMza6KyRBIRS4DPAJcDdwG/iYiZkiZJ2i1X2xG4W9I9wHrA8bn8AuBe4HZSO8r0iPgDqeH9ckkzgNtIp8J+XtU2mJlZc4ro2WzxytPV1RXd3d3tDsPMrKNImhoRXc3q+c52MzNriROJmZm1xInEzMxa4kRiZmYtcSIxM7OWOJGYmVlLnEjMzKwlTiRmZtYSJxIzM2uJE4mZmbXEicTMzFqyXPS1JWk+8EA/LGoE8Eg/LKe/Dca4HFM5jqm8wRjXKz2msRHR9IFOy0Ui6S+Sust0YDbQBmNcjqkcx1TeYIzLMSU+tWVmZi1xIjEzs5Y4kfTNqe0OoBeDMS7HVI5jKm8wxuWYcBuJmZm1yEckZmbWEicSMzNriRNJHZJ2kXS3pFmSvlxn+tsl3SppiaS9B0lMh0m6U9IMSVdLGjtI4vqkpNsl3SbpBknj2x1Tod7ekkJS5ZdKlthPB0man/fTbZI+1u6Ycp0P5c/VTEm/bndMkr5f2Ef3SFpYdUwl4xoj6RpJ0/L/4K6DIKax+btghqTJkkZVFkxEeCgMwBDgXmATYEVgOjC+R51xwATgbGDvQRLTO4BX5fFPAecPkrjWKIzvBvyp3THleqsD1wFTgK52xwQcBPyo6vesjzFtCkwD1sqv1213TD3qfxY4fZDsq1OBT+Xx8cD9gyCm3wIH5vF3Ar+sKh4fkbzctsCsiLgvIp4DzgN2L1aIiPsjYgbw/CCK6ZqIeDq/nAJU9+ujb3E9UXi5KlD11R1NY8q+AXwbeLbiePoS00AqE9PHgR9HxGMAEfHwIIipaB/g3IpjKhtXAGvk8TWBeYMgpvHA1Xn8mjrT+40TycttBMwuvJ6Ty9qprzEdAvyx0oiSUnFJ+rSke0lf3J9rd0yStgJGR8SlFcdSOqZsr3wa4gJJowda3AeJAAAHcElEQVRBTK8FXivpRklTJO0yCGIC0mkbYGPgzxXHVDauY4D9JM0BLiMdLbU7punAXnn8A8DqktapIhgnkpdTnbJ2XyNdOiZJ+wFdwEmVRpRXV6fsZXFFxI8j4tXAkcDX2hmTpBWA7wNfrDiOojL76Q/AuIiYAFwFnDUIYhpKOr21I+nX/2mShrc5ppqPABdExNIK46kpE9c+wJkRMQrYFfhl/qy1M6bDgR0kTQN2AOYCS6oIxonk5eYAxV+Do6j+MLWZUjFJehfwVWC3iPj3YImr4Dxgj0ojah7T6sDrgcmS7ge2By6puMG96X6KiEcL79nPgW0qjKdUTLnOxRGxOCL+AdxNSiztjKnmIwzMaS0oF9chwG8AIuImYGVS54ltiyki5kXEnhGxFel7gYh4vJJoqm6o6rSB9CvsPtJhc60Ra4te6p7JwDS2N40J2IrU+LbpYNpXxXiA9wPd7Y6pR/3JVN/YXmY/bVAY/wAwZRDEtAtwVh4fQTqVsk673ztgM+B+8g3VVQ8l99UfgYPy+OtIX+qVxVcyphHACnn8eGBSZfEMxBvRaQPp0PSe/MX81Vw2ifRLH+BNpF8ETwGPAjMHQUxXAf8CbsvDJYNkX/0vMDPHdE2jL/WBiqlH3coTScn9dELeT9Pzftp8EMQk4HvAncDtwEfaHVN+fQxwYtWx9HFfjQduzO/fbcB7BkFMewN/z3VOA1aqKhZ3kWJmZi1xG4mZmbXEicTMzFriRGJmZi1xIjEzs5Y4kZiZWUucSGyZSFpa6IX1Nknj+mGZexR7B5Y0Kd9kWRlJ5+ZuSf67USx9WN5ujXoc7g+STmsW27LG306SvrIM8xwk6UdVxGPl+fJfWyaSnoyI1RpMHxoRfeqOQdKZwKURcUGr8ZVc3/rAzRHxsi73G8WyLNs20AZyX0oaEoWuSpZ1/zT7TPUyz0Gk+4A+09f1Wf/xEYn1m/zr8LeS/gBcIWm1/DyEW/MzSXYv1D0gHwlMl/RLSf9B6mb+pHyE82pJZyo/70XSTvlZD7dLOl3SSrn8fknHFtaxeZ24VpZ0Rp4+TdI78qQrgHXz+t5WqF8vlsmSvinpWuDzkt4v6ea8vKskrVfYBz/K42dKOlnSXyTdpzrPrpE0TtLfJJ1V6LDxVU22eXKtSxdJT0o6Pu/HKZLW6yX+z+nF59WcVyeOIZK+k9c1Q9JnS+z3r0u6Afhgnf3zwntXizP/3VHSdZIuzPGcImkFSScCq+R4z8l195N0Sy77maQhufxgpWeRXAu8pdFn0gbIQN4d6uGVMwBLefEu+gtz2UGkO/7Xzq+Hkp9HQuquYRbpbuktSP02jcjTavXPpNDlTO01qd+i2cBrc/nZwBfy+P3AZ/P4fwGn1Yn1i8AZeXxz4MG8zHHAHb1sX89YJgM/KbxeixeP6D8GfLewD35UWMZvST/YxpO6/e65nnGkzvbekl+fTupsr9E2TybfjZ/nfX8e/zbwtV7in0e+sxkYXieOTwG/A4bW3pMS+/1LDfZPz/U/mf/uSOq6fxPSMzWurNWr1cnjryN1ZDksv/4JcACwQX7/RpK6BrmRAXyOi4f6g49IbFk9ExFb5uEDhfIrI2JBHhfwTUkzSF24bASsR3rIzgUR8QhAoX5vNgP+ERH35NdnAW8vTP99/juV9MXc01uBX+Z1/Q14gNRFel+dXxgfBVwu6XbgCFJyrOeiiHg+Iu4kbXs9syPixjz+qxxvs22ueQ6odYff2/YDzADOUeodut5pp3cBp0Q+JZXfk2YxnP/SRbzsdW9uifQcjaWkjhffWqfOTqSOK/8q6bb8ehNgO2ByRMyP9ByOsuu0CjmRWH97qjC+L+mX4zYRsSWpL7CVSQmmL41z9brMLqr1mruUdBTU1/nLKm7bD0m/hN8AfIK0XY1iaxRHz30RDer2tDjyT3Z6336A9wI/Jn05T5XUs16996RZDE81eL2E/P0iSaSjh5p629uTSB1G1n6sbBYRxzSob23kRGJVWhN4OCIW53aJWqP21cCHlB+yI2ntXL6I1M17T38Dxkl6TX69P3BtH+K4jpTUkPRaYAzp1FojvcVSsybp+Q4AB/YhlnrGSHpzHt8HuIHWt/mF+JWeizE6Iq4BvgQMB3o2al8BfLKWYPJ70koM9/NiV/i7A8MK07aVtHGO68Ok7QVYLKlW72pgb0nr1uJRepjVzcCOktbJdT9YMh6rkBOJVekcoEtSN+mL/G8AETGT1K31tZKmk3qYhfS8kiNy4+6rawuJiGeBg4Hf5lNJzwOn9CGOnwBD8rznk7r7bva8lrqxFByT47keeKQPsdRzF3BgPgW4NvDTftjmF+InPUPkV3k504DvR8TCHvVPI7U9zMjvyX+2GMPPSQ9VuoV0Oqp4tHITcCJwB/AP4MJcfmpe/zn5VODXSBdtzCC1pWwQEQ+R9v1NpNOlt5aMxyrky3/N2kjp/ptLI+L1bQ5lQEjaETg8It7X7lis//iIxMzMWuIjEjMza4mPSMzMrCVOJGZm1hInEjMza4kTiZmZtcSJxMzMWvL/2XSVsoxiriYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(frac_array, loss_pearson)\n",
    "plt.xlabel('Fraction of train points corrupted')\n",
    "plt.ylabel('Pearson Correlation b/w S&G')\n",
    "plt.title('Using cross-entropy loss function')\n",
    "plt.savefig('./images/corr/loss_pearson.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(frac_array, acc_pearson)\n",
    "plt.xlabel('Fraction of train points corrupted')\n",
    "plt.ylabel('Pearson Correlation b/w S&G')\n",
    "plt.title('Using 0/1 loss function')\n",
    "plt.savefig('./images/corr/acc_pearson.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0.5000000000000001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-ee626b14bd70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfrac_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msg_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrac_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0.5000000000000001"
     ]
    }
   ],
   "source": [
    "frac_array = np.arange(0.1, 1.0, 0.2)\n",
    "x, y = sg_dict[]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
